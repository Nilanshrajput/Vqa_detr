{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detr_vilbert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN59nvhR+M4/TDtgJQdtU7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a6bb569d93b42959512b72fd28e568e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07708294fc044b9eae440a142178949f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b22f03a89fb742df81a24e4b6e01e7eb",
              "IPY_MODEL_68bae10d0af74a08aab0e20e26d4f9e9"
            ]
          }
        },
        "07708294fc044b9eae440a142178949f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b22f03a89fb742df81a24e4b6e01e7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7efd50df1d7e4301b5e18dab085c1787",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f085b98455cf4a81bddea137db287495"
          }
        },
        "68bae10d0af74a08aab0e20e26d4f9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a1c8ce281f14b97b5c064470bc0c266",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_993d664854b8467082c7a88de6b368c5"
          }
        },
        "7efd50df1d7e4301b5e18dab085c1787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f085b98455cf4a81bddea137db287495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a1c8ce281f14b97b5c064470bc0c266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "993d664854b8467082c7a88de6b368c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c48cfc6bd7c46f08bc01a5331e1423d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53ee4ea41c1b45dfbb51c95b462f3f8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4cb8f49614dd4791b504df85c85ff348",
              "IPY_MODEL_72ee39bafc2f4fbbbe4811e42e788c27"
            ]
          }
        },
        "53ee4ea41c1b45dfbb51c95b462f3f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cb8f49614dd4791b504df85c85ff348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bfd3731293e94cb88bbb324113017044",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 83100797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 83100797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b44315d621594ae4ae1473ec56a427e8"
          }
        },
        "72ee39bafc2f4fbbbe4811e42e788c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ece90e46f1304043ad4b0a8284b50f36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 79.3M/79.3M [00:03&lt;00:00, 22.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a43457e6ab5426897da0c968c2d0fcb"
          }
        },
        "bfd3731293e94cb88bbb324113017044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b44315d621594ae4ae1473ec56a427e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ece90e46f1304043ad4b0a8284b50f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a43457e6ab5426897da0c968c2d0fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abaaad1b05c24240b8d2088d5e2e443d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33894f0591fc4d54a9827aedfacd2dfc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ab96f3ad2c1430a8e6fc366b377874c",
              "IPY_MODEL_24c357a3464c4a94939abd03f20bac5d"
            ]
          }
        },
        "33894f0591fc4d54a9827aedfacd2dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "7ab96f3ad2c1430a8e6fc366b377874c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13cc82156eea45cd8c1c746e77ca631b",
            "_dom_classes": [],
            "description": "Epoch 1:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 27735,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_243c03d3fc644cd2ad071e31b18fb154"
          }
        },
        "24c357a3464c4a94939abd03f20bac5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9521d88426204aa2b41d2c59002f6570",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/27735 [04:42&lt;2179:07:20, 282.86s/it, loss=11.787, v_num=4]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cbfb9958679400db31a02ce9e4c2b16"
          }
        },
        "13cc82156eea45cd8c1c746e77ca631b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "243c03d3fc644cd2ad071e31b18fb154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9521d88426204aa2b41d2c59002f6570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cbfb9958679400db31a02ce9e4c2b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/Vqa_detr/blob/master/DETR_Vqa_pytlightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqe_0nc5dyAq",
        "colab_type": "text"
      },
      "source": [
        "# Object Detection with DETR - a minimal implementation\n",
        "\n",
        "In this notebook we show a demo of DETR (Detection Transformer), with slight differences with the baseline model in the paper.\n",
        "\n",
        "We show how to define the model, load pretrained weights and visualize bounding box and class predictions.\n",
        "\n",
        "Let's start with some common imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDHEKd8CDk3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "a60d8025-a902-4cbc-87c0-eff72c572e7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBlE2BQfiSNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62ce9e5c-88b1-449e-c5a1-45db8be56ca0"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4264  100  4264    0     0  68774      0 --:--:-- --:--:-- --:--:-- 68774\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-nightly ...\n",
            "Uninstalling torch-1.5.0+cu101:\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "  Successfully uninstalled torch-1.5.0+cu101\n",
            "Uninstalling torchvision-0.6.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 89.7 MiB/ 89.7 MiB]                                                \n",
            "Operation completed over 1 objects/89.7 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][117.4 MiB/117.4 MiB]                                                \n",
            "Operation completed over 1 objects/117.4 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  1.7 MiB/  1.7 MiB]                                                \n",
            "Operation completed over 1 objects/1.7 MiB.                                      \n",
            "Processing ./torch-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+6bdfd6a\n",
            "Processing ./torch_xla-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+3c308cd\n",
            "Processing ./torchvision-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.6.0a0+6bdfd6a)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+2cfc360\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (314 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saZ2BV_Ag0uc",
        "colab_type": "code",
        "outputId": "2a09352a-c0de-48c2-9160-3e074ab9d4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-lightning"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 3.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 20.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=615c7793e41948167c203108d338319204c9fd8ea1c5e6259e8571707613a87d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n",
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/ab/561d1fa6e5af30b2fd7cb4001f93eb08531e1b72976f13eebf7f7cdc021c/pytorch_lightning-0.7.6-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.18.5)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.2.2)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=3.13 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (3.13)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.6.0a0+6bdfd6a)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (47.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.29.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.6.0.post3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.34.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning) (1.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=bcf8ce555a96f5418ffa3dd6b0ce2f713c6bc95a76fae8ba64552f0cad083e59\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "Installing collected packages: future, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed future-0.18.2 pytorch-lightning-0.7.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf59UNQ37QhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch import nn\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "import json\n",
        "import tqdm\n",
        "\n",
        "import logging\n",
        "from argparse import Namespace\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from transformers.tokenization_bert import BertTokenizer\n",
        "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel, BertModel\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torchtext\n",
        "\n",
        "from pytorch_lightning.core.lightning import LightningModule\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "\n",
        "\n",
        "import pdb\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSnU5JFxGeDe",
        "colab_type": "text"
      },
      "source": [
        "## DETR\n",
        "Here is a minimal implementation of DETR:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h91rsIPl7tVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DETRdemo(nn.Module):\n",
        "    \"\"\"\n",
        "    Demo DETR implementation.\n",
        "\n",
        "    Demo implementation of DETR in minimal number of lines, with the\n",
        "    following differences wrt DETR in the paper:\n",
        "    * learned positional encoding (instead of sine)\n",
        "    * positional encoding is passed at input (instead of attention)\n",
        "    * fc bbox predictor (instead of MLP) nj\n",
        "    The model achieves ~40 AP on COCO val5k and runs at ~28 FPS on Tesla V100.\n",
        "    Only batch size 1 supported.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, hidden_dim=256, nheads=8,\n",
        "                 num_encoder_layers=6, num_decoder_layers=6):\n",
        "        super().__init__()\n",
        "\n",
        "        # create ResNet-50 backbone\n",
        "        self.backbone = resnet50()\n",
        "        del self.backbone.fc\n",
        "\n",
        "        # create conversion layer\n",
        "        self.conv = nn.Conv2d(2048, hidden_dim, 1)\n",
        "\n",
        "        # create a default PyTorch transformer\n",
        "        self.transformer = nn.Transformer(\n",
        "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
        "\n",
        "        # prediction heads, one extra class for predicting non-empty slots\n",
        "        # note that in baseline DETR linear_bbox layer is 3-layer MLP\n",
        "        self.linear_class = nn.Linear(hidden_dim, num_classes + 1)\n",
        "        self.linear_bbox = nn.Linear(hidden_dim, 4)\n",
        "\n",
        "        # output positional encodings (object queries)\n",
        "        self.query_pos = nn.Parameter(torch.rand(100, hidden_dim))\n",
        "\n",
        "        # spatial positional encodings\n",
        "        # note that in baseline DETR we use sine positional encodings\n",
        "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
        "        self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # propagate inputs through ResNet-50 up to avg-pool layer\n",
        "        x = self.backbone.conv1(inputs)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "        # convert from 2048 to 256 feature planes for the transformer\n",
        "        h = self.conv(x)\n",
        "        bb_ot = h\n",
        "        \n",
        "        # construct positional encodings\n",
        "        \"\"\"        H, W = h.shape[-2:]\n",
        "        pos = torch.cat([\n",
        "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
        "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
        "        ], dim=-1).flatten(0, 1).unsqueeze(1)\"\"\"\n",
        "\n",
        "        bs,_,H, W = h.shape\n",
        "        pos = torch.cat([\n",
        "        self.col_embed[:W].unsqueeze(0).unsqueeze(1).repeat(bs,H, 1, 1),\n",
        "        self.row_embed[:H].unsqueeze(0).unsqueeze(2).repeat(bs,1, W, 1),\n",
        "        ], dim=-1).flatten(1, 2)\n",
        "\n",
        "\n",
        "        #print(self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1))\n",
        "        # propagate through the transformer\n",
        "        #shape changed to (W*H,bs,hidden_dim) for both pos and h\n",
        "        h = self.transformer(pos.permute(1, 0, 2) + 0.1 * h.flatten(2).permute(2, 0, 1),\n",
        "                             self.query_pos.unsqueeze(1).repeat(1,bs,1)).transpose(0, 1)\n",
        "        \n",
        "        # finally project transformer outputs to class labels and bounding boxes\n",
        "        return {'pred_logits': self.linear_class(h), \n",
        "                'pred_boxes': self.linear_bbox(h).sigmoid(),\n",
        "                'decoder_out':h,\n",
        "                'res_out':bb_ot}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dComoNKgtMEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "ae0020e3-56e7-4bb6-e090-f675e07d5fac"
      },
      "source": [
        "class VQA_DETR(LightningModule):\n",
        "    def __init__(self,hparams,vqa_dataset, num_ans,hidden_size=256, num_attention_heads = 8, num_hidden_layers = 6):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hparams = hparams\n",
        "        self.vqa_dataset = vqa_dataset\n",
        "\n",
        "        self.bert__decoder_config = BertConfig(is_decoder = True,hidden_size=hidden_size, num_attention_heads=num_attention_heads, num_hidden_layers=num_hidden_layers)\n",
        "        #self.enc_dec_config = EncoderDecoderConfig.from_encoder_decoder_configs(encoder_config= self.bert_config, decoder_config= self.bert_config)\n",
        "        #self.model = EncoderDecoderModel(config= self.enc_dec_config)\n",
        "        self.bert_decoder = BertModel(config=self.bert__decoder_config)\n",
        "\n",
        "        self.detr = DETRdemo(num_classes=91)\n",
        "        state_dict = torch.hub.load_state_dict_from_url(\n",
        "            url='https://dl.fbaipublicfiles.com/detr/detr_demo-da2a99e9.pth',\n",
        "            map_location='cpu', check_hash=True)\n",
        "        self.detr.load_state_dict(state_dict)\n",
        "        #self.detr  = self.detr.cuda()\n",
        "\n",
        "        self.classifier  = nn.Linear(hidden_size*2,num_ans)\n",
        "\n",
        "        self.drop_out = nn.Dropout(p=0.2)\n",
        "        self.log_softmax = nn.LogSoftmax().cuda()\n",
        "        \n",
        "\n",
        "    def forward(self,img, q_ids):\n",
        "        \n",
        "        img_ecs = self.detr(img)['decoder_out'].flatten(2)\n",
        "        o1,_ = self.bert_decoder(input_ids = q_ids, encoder_hidden_states = img_ecs)\n",
        "\n",
        "        mean_pool = torch.mean(o1,1)\n",
        "        max_pool,_ = torch.max(o1,1)\n",
        "        cat = torch.cat((mean_pool, max_pool),1)\n",
        "\n",
        "        bo = self.drop_out(cat)\n",
        "        output = self.classifier(bo)\n",
        "        \n",
        "        nll = -self.log_softmax(output)\n",
        "\n",
        "        return {'logits':output,'nll':nll}\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        im,q,a  = batch\n",
        "        ids = q[\"ids\"]\n",
        "\n",
        "        outputs = self(im,ids)\n",
        "        output =outputs['logits']\n",
        "\n",
        "        loss = self.loss_fn(output, a)\n",
        "        tensorboard_logs = {'train_loss': loss}\n",
        "\n",
        "        return {'loss': loss, 'log': tensorboard_logs}\n",
        "\n",
        "    def loss_fn(self, outputs, targets):\n",
        "        return nn.CrossEntropyLoss()(outputs, targets)\n",
        "\n",
        "    @lru_cache()\n",
        "    def total_steps(self):\n",
        "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        param_optimizer = list(self.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
        "        ]\n",
        "\n",
        "        optimizer = AdamW(optimizer_parameters, lr=self.hparams.lr)\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=self.total_steps(),\n",
        "        )\n",
        "\n",
        "        return [optimizer],  [{\"scheduler\": scheduler, \"interval\": \"step\"}]\n",
        "\n",
        "    def train_dataloader(self):\n",
        "\n",
        "        loader = DataLoader(self.vqa_dataset, batch_size = self.hparams.batch_size,num_workers=1, shuffle= True)\n",
        "        return loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ae55072099bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mVQA_DETR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvqa_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LightningModule' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SoSX5_T7AQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip\" -c -O 'v2_Annotations_Train_mscoco.zip'\n",
        "!unzip /content/v2_Annotations_Train_mscoco.zip\n",
        "!wget --header=\"Host: images.cocodataset.org\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"http://images.cocodataset.org/zips/train2014.zip\" -c -O 'train2014.zip'\n",
        "!unzip train2014.zip\n",
        "!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip\" -c -O 'v2_Questions_Train_mscoco.zip'\n",
        "!unzip v2_Questions_Train_mscoco.zip\n",
        "##!wget --header=\"Host: images.cocodataset.org\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"http://images.cocodataset.org/zips/val2014.zip\" -c -O 'val2014.zip'\n",
        "#!unzip /content/val2014.zip\n",
        "#!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip\" -c -O 'v2_Questions_Val_mscoco.zip'\n",
        "#!unzip v2_Questions_Val_mscoco.zip\n",
        "#!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Test_mscoco.zip\" -c -O 'v2_Questions_Test_mscoco.zip'\n",
        "#!unzip v2_Questions_Test_mscoco.zip\n",
        "#!wget --header=\"Host: images.cocodataset.org\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"http://images.cocodataset.org/zips/test2015.zip\" -c -O 'test2015.zip'\n",
        "#!unzip test2015.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiPadTPQbG0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def assert_eq(real, expected):\n",
        "    assert real == expected, \"%s (true) vs %s (expected)\" % (real, expected)\n",
        "\n",
        "def _create_entry(question, answer):\n",
        "    answer.pop(\"image_id\")\n",
        "    answer.pop(\"question_id\")\n",
        "    entry = {\n",
        "        \"question_id\": question[\"question_id\"],\n",
        "        \"image_id\": question[\"image_id\"],\n",
        "        \"question\": question[\"question\"],\n",
        "        \"answer\": [a['answer'] for a in answer['answers']],\n",
        "    }\n",
        "    return entry\n",
        "\n",
        "def _load_dataset(dataroot, name):\n",
        "    \"\"\"Load entries\n",
        "    dataroot: root path of dataset\n",
        "    name: 'train', 'val', 'trainval', 'minsval'\n",
        "    \"\"\"\n",
        "    if name == 'train' or name == 'val':\n",
        "        question_path = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % name)\n",
        "        questions = sorted(json.load(open(question_path))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "        answer_path = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % name)\n",
        "        answers = json.load(open(answer_path, \"rb\"))[\"annotations\"]\n",
        "        answers = sorted(answers, key=lambda x: x[\"question_id\"])\n",
        "\n",
        "    elif name  == 'trainval':\n",
        "        question_path_train = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'train')\n",
        "        questions_train = sorted(json.load(open(question_path_train))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "        answer_path_train = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'train')\n",
        "        answers_train = json.load(open(answer_path_train, \"rb\"))[\"annotations\"]\n",
        "        answers_train = sorted(answers_train, key=lambda x: x[\"question_id\"])\n",
        "\n",
        "        question_path_val = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'val')\n",
        "        questions_val = sorted(json.load(open(question_path_val))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "        answer_path_val = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'val')\n",
        "        answers_val = json.load(open(answer_path_val, \"rb\"))[\"annotations\"]\n",
        "        answers_val = sorted(answers_val, key=lambda x: x[\"question_id\"])\n",
        "        questions = questions_train + questions_val[:-3000]\n",
        "        answers = answers_train + answers_val[:-3000]\n",
        "\n",
        "    elif name == 'minval':\n",
        "        question_path_val = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'val')\n",
        "        questions_val = sorted(json.load(open(question_path_val))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "        answer_path_val = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'val')\n",
        "        answers_val = json.load(open(answer_path_val, \"rb\"))[\"annotations\"]\n",
        "        answers_val = sorted(answers_val, key=lambda x: x[\"question_id\"])        \n",
        "        questions = questions_val[-3000:]\n",
        "        answers = answers_val[-3000:]\n",
        "\n",
        "    elif name == 'test':\n",
        "        question_path_test = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2015_questions.json\" % 'test')\n",
        "        questions_test = sorted(json.load(open(question_path_test))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "        questions = questions_test\n",
        "    else:\n",
        "        assert False, \"data split is not recognized.\"\n",
        "\n",
        "    if 'test' in name:\n",
        "        entries = []\n",
        "        for question in questions:\n",
        "            entries.append(question)\n",
        "    else:\n",
        "        assert_eq(len(questions), len(answers))\n",
        "        entries = []\n",
        "        for question, answer in zip(questions, answers):\n",
        "            assert_eq(question[\"question_id\"], answer[\"question_id\"])\n",
        "            assert_eq(question[\"image_id\"], answer[\"image_id\"])\n",
        "            entries.append(_create_entry(question, answer))\n",
        "    return entries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_KSLg6prP4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entries = _load_dataset(dataroot='/content/',name='train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdewFhEzUU1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile a list of all the answers\n",
        "all_answers  = set()\n",
        "for a in entries:\n",
        "    all_answers.update(a['answer'])\n",
        "all_answers=list(all_answers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Q_quxQmxOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_to_index = dict()\n",
        "for i,answer in enumerate(all_answers):\n",
        "    answer_to_index[answer]=i\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBlfQ2YngeTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VQA(data.Dataset):\n",
        "    \"\"\" VQA dataset, open-ended \"\"\"\n",
        "    def __init__(self, root, answer_to_index, tokenizer ,split = 'train', max_len = 20):\n",
        "        super(VQA, self).__init__()\n",
        "\n",
        "\n",
        "        self.root = root\n",
        "        self.answer_to_index = answer_to_index\n",
        "        self.split = split\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.entries = self._load_dataset( self.root, self.split)\n",
        "\n",
        "         # standard PyTorch mean-std input image normalization\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize(size=(800,800)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.id_to_image_fname = self._find_iamges()\n",
        "\n",
        "\n",
        "    def assert_eq(self,real, expected):\n",
        "        assert real == expected, \"%s (true) vs %s (expected)\" % (real, expected)\n",
        "\n",
        "    def _create_entry(self,question, answer):\n",
        "        answer.pop(\"image_id\")\n",
        "        answer.pop(\"question_id\")\n",
        "        entry = {\n",
        "            \"question_id\": question[\"question_id\"],\n",
        "            \"image_id\": question[\"image_id\"],\n",
        "            \"question\": question[\"question\"],\n",
        "            \"answer\": [a['answer'] for a in answer['answers']],\n",
        "        }\n",
        "        return entry\n",
        "\n",
        "    def _load_dataset(self,dataroot, name):\n",
        "        \"\"\"Load entries\n",
        "        dataroot: root path of dataset\n",
        "        name: 'train', 'val', 'trainval', 'minsval'\n",
        "        \"\"\"\n",
        "        if name == 'train' or name == 'val':\n",
        "            question_path = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % name)\n",
        "            questions = sorted(json.load(open(question_path))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "            answer_path = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % name)\n",
        "            answers = json.load(open(answer_path, \"rb\"))[\"annotations\"]\n",
        "            answers = sorted(answers, key=lambda x: x[\"question_id\"])\n",
        "\n",
        "        elif name  == 'trainval':\n",
        "            question_path_train = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'train')\n",
        "            questions_train = sorted(json.load(open(question_path_train))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "            answer_path_train = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'train')\n",
        "            answers_train = json.load(open(answer_path_train, \"rb\"))[\"annotations\"]\n",
        "            answers_train = sorted(answers_train, key=lambda x: x[\"question_id\"])\n",
        "\n",
        "            question_path_val = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'val')\n",
        "            questions_val = sorted(json.load(open(question_path_val))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "            answer_path_val = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'val')\n",
        "            answers_val = json.load(open(answer_path_val, \"rb\"))[\"annotations\"]\n",
        "            answers_val = sorted(answers_val, key=lambda x: x[\"question_id\"])\n",
        "            questions = questions_train + questions_val[:-3000]\n",
        "            answers = answers_train + answers_val[:-3000]\n",
        "\n",
        "        elif name == 'minval':\n",
        "            question_path_val = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'val')\n",
        "            questions_val = sorted(json.load(open(question_path_val))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "            answer_path_val = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'val')\n",
        "            answers_val = json.load(open(answer_path_val, \"rb\"))[\"annotations\"]\n",
        "            answers_val = sorted(answers_val, key=lambda x: x[\"question_id\"])        \n",
        "            questions = questions_val[-3000:]\n",
        "            answers = answers_val[-3000:]\n",
        "\n",
        "        elif name == 'test':\n",
        "            question_path_test = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2015_questions.json\" % 'test')\n",
        "            questions_test = sorted(json.load(open(question_path_test))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
        "            questions = questions_test\n",
        "        else:\n",
        "            assert False, \"data split is not recognized.\"\n",
        "\n",
        "        if 'test' in name:\n",
        "            entries = []\n",
        "            for question in questions:\n",
        "                entries.append(question)\n",
        "        else:\n",
        "            assert_eq(len(questions), len(answers))\n",
        "            entries = []\n",
        "            for question, answer in zip(questions, answers):\n",
        "                assert_eq(question[\"question_id\"], answer[\"question_id\"])\n",
        "                assert_eq(question[\"image_id\"], answer[\"image_id\"])\n",
        "                entries.append(_create_entry(question, answer))\n",
        "        return entries\n",
        "\n",
        "\n",
        "\n",
        "    def _encode_question(self, question):\n",
        "        \"\"\" Turn a question into a vector of indices and a question length \"\"\"\n",
        "        \n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            question,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            )\n",
        "\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        padding_length = self.max_len - len(ids)\n",
        "        ids += ([0]*padding_length)\n",
        "        mask += ([0]*padding_length)\n",
        "        token_type_ids += ([0]*padding_length)\n",
        "        \n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \n",
        "        }\n",
        "\n",
        "    def _encode_ansfor_bert(self, answers):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def _encode_answers(self, answers):\n",
        "        \"\"\" Turn an answer into a vector \"\"\"\n",
        "        # answer vec will be a vector of answer counts to determine which answers will contribute to the loss.\n",
        "        # this should be multiplied with 0.1 * negative log-likelihoods that a model produces and then summed up\n",
        "        # to get the loss that is weighted by how many humans gave that answer\n",
        "        answer_vec = torch.zeros(len(self.answer_to_index),dtype=torch.long)\n",
        "        for answer in answers:\n",
        "            index = self.answer_to_index.get(answer)\n",
        "            if index is not None:\n",
        "                answer_vec[index] += 1\n",
        "        _,idx = answer_vec.max(dim = 0)\n",
        "        idx = torch.tensor(idx, dtype = torch.long)\n",
        "\n",
        "        return idx\n",
        "\n",
        "   \n",
        "    def _find_iamges(self):\n",
        "        id_to_filename = {}\n",
        "        imgs_folder = os.path.join(self.root,'train2014')\n",
        "        for filename in os.listdir(imgs_folder):\n",
        "            if not filename.endswith('.jpg'):\n",
        "                continue\n",
        "            id_and_extension = filename.split('_')[-1]\n",
        "            id = int(id_and_extension.split('.')[0])\n",
        "            id_to_filename[id] = os.path.join(imgs_folder,filename)\n",
        "        return id_to_filename\n",
        "\n",
        "\n",
        "    def _load_image(self, image_id):\n",
        "        \"\"\" Load an image \"\"\"\n",
        "\n",
        "        img_path = self.id_to_image_fname[image_id]\n",
        "        img  = Image.open(img_path)\n",
        "        img = np.asarray(img)\n",
        "        \n",
        "        if len(img.shape)==2:\n",
        "            print(img.shape)\n",
        "            img=np.expand_dims(img, axis=-1)\n",
        "            \n",
        "            img = np.repeat(img,3, axis = -1)\n",
        "            print(img.shape)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "       \n",
        "        entry  = self.entries[item]\n",
        "        q = entry['question']\n",
        "        a = self._encode_answers(entry['answer'])\n",
        "        image_id = entry['image_id']\n",
        "\n",
        "        img = self._load_image(image_id)\n",
        "        img = Image.fromarray(img)\n",
        "        img = self.transform(img)\n",
        "        #question_id = entry['question_id']\n",
        "        q= self._encode_question(q)\n",
        "\n",
        "        return img, q, a\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.entries)\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batch):\n",
        "        \"\"\"The collat_fn method to be used by the\n",
        "        PyTorch data loader.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Unzip the batch\n",
        "\n",
        "        imgs,qs, answers = list(zip(*batch))\n",
        "\n",
        "        # concatenate the vectors\n",
        "        imgs = torch.stack(imgs)\n",
        "        \n",
        "        #concatenate the labels\n",
        "        q = torch.stack(qs)\n",
        "\n",
        "        a = torch.stack(answers)\n",
        "        \n",
        "        return imgs, q, a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff9kOL6KIncK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "6a6bb569d93b42959512b72fd28e568e",
            "07708294fc044b9eae440a142178949f",
            "b22f03a89fb742df81a24e4b6e01e7eb",
            "68bae10d0af74a08aab0e20e26d4f9e9",
            "7efd50df1d7e4301b5e18dab085c1787",
            "f085b98455cf4a81bddea137db287495",
            "7a1c8ce281f14b97b5c064470bc0c266",
            "993d664854b8467082c7a88de6b368c5"
          ]
        },
        "outputId": "443fb52a-000b-49fc-fa57-1579fb4b6ff5"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a6bb569d93b42959512b72fd28e568e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhYh98-8GROJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vqa_data = VQA(root='/content', answer_to_index=answer_to_index,split= 'train', tokenizer=bert_tokenizer, max_len=15 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKR94pUILXJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = Namespace(\n",
        "    batch_size=2,\n",
        "    warmup_steps=100,\n",
        "    epochs=3,\n",
        "    lr=3e-5,\n",
        "    accumulate_grad_batches=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhbtt7a2OfCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "7c48cfc6bd7c46f08bc01a5331e1423d",
            "53ee4ea41c1b45dfbb51c95b462f3f8e",
            "4cb8f49614dd4791b504df85c85ff348",
            "72ee39bafc2f4fbbbe4811e42e788c27",
            "bfd3731293e94cb88bbb324113017044",
            "b44315d621594ae4ae1473ec56a427e8",
            "ece90e46f1304043ad4b0a8284b50f36",
            "7a43457e6ab5426897da0c968c2d0fcb"
          ]
        },
        "outputId": "3d7eeb6b-8baf-4c60-c530-94df378f6104"
      },
      "source": [
        "vqa_detr = VQA_DETR(num_ans=len(answer_to_index),hparams=hparams, vqa_dataset= vqa_data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr_demo-da2a99e9.pth\" to /root/.cache/torch/hub/checkpoints/detr_demo-da2a99e9.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c48cfc6bd7c46f08bc01a5331e1423d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=83100797.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXeflNl8HEy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_loader = DataLoader(vqa_data, batch_size = hparams.batch_size, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGZ-OqgvOe-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "abaaad1b05c24240b8d2088d5e2e443d",
            "33894f0591fc4d54a9827aedfacd2dfc",
            "7ab96f3ad2c1430a8e6fc366b377874c",
            "24c357a3464c4a94939abd03f20bac5d",
            "13cc82156eea45cd8c1c746e77ca631b",
            "243c03d3fc644cd2ad071e31b18fb154",
            "9521d88426204aa2b41d2c59002f6570",
            "9cbfb9958679400db31a02ce9e4c2b16"
          ]
        },
        "outputId": "888d22a3-3935-462e-d026-80db15f89be3"
      },
      "source": [
        "trainer = Trainer(num_tpu_cores=8, default_save_path='/gdrive/My Drive/dl_projects/VQA_detr')\n",
        "trainer.fit(vqa_detr)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "No environment variable for node rank defined. Set as 0.\n",
            "training on 8 TPU cores\n",
            "INIT TPU local core: 0, global rank: 0\n",
            "INIT TPU local core: 1, global rank: 1\n",
            "INIT TPU local core: 5, global rank: 5\n",
            "INIT TPU local core: 3, global rank: 3\n",
            "INIT TPU local core: 7, global rank: 7\n",
            "INIT TPU local core: 6, global rank: 6\n",
            "INIT TPU local core: 2, global rank: 2\n",
            "INIT TPU local core: 4, global rank: 4\n",
            "\n",
            "    | Name                                                         | Type                    | Params\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "0   | bert_decoder                                                 | BertModel               | 20 M  \n",
            "1   | bert_decoder.embeddings                                      | BertEmbeddings          | 7 M   \n",
            "2   | bert_decoder.embeddings.word_embeddings                      | Embedding               | 7 M   \n",
            "3   | bert_decoder.embeddings.position_embeddings                  | Embedding               | 131 K \n",
            "4   | bert_decoder.embeddings.token_type_embeddings                | Embedding               | 512   \n",
            "5   | bert_decoder.embeddings.LayerNorm                            | LayerNorm               | 512   \n",
            "6   | bert_decoder.embeddings.dropout                              | Dropout                 | 0     \n",
            "7   | bert_decoder.encoder                                         | BertEncoder             | 12 M  \n",
            "8   | bert_decoder.encoder.layer                                   | ModuleList              | 12 M  \n",
            "9   | bert_decoder.encoder.layer.0                                 | BertLayer               | 2 M   \n",
            "10  | bert_decoder.encoder.layer.0.attention                       | BertAttention           | 263 K \n",
            "11  | bert_decoder.encoder.layer.0.attention.self                  | BertSelfAttention       | 197 K \n",
            "12  | bert_decoder.encoder.layer.0.attention.self.query            | Linear                  | 65 K  \n",
            "13  | bert_decoder.encoder.layer.0.attention.self.key              | Linear                  | 65 K  \n",
            "14  | bert_decoder.encoder.layer.0.attention.self.value            | Linear                  | 65 K  \n",
            "15  | bert_decoder.encoder.layer.0.attention.self.dropout          | Dropout                 | 0     \n",
            "16  | bert_decoder.encoder.layer.0.attention.output                | BertSelfOutput          | 66 K  \n",
            "17  | bert_decoder.encoder.layer.0.attention.output.dense          | Linear                  | 65 K  \n",
            "18  | bert_decoder.encoder.layer.0.attention.output.LayerNorm      | LayerNorm               | 512   \n",
            "19  | bert_decoder.encoder.layer.0.attention.output.dropout        | Dropout                 | 0     \n",
            "20  | bert_decoder.encoder.layer.0.crossattention                  | BertAttention           | 263 K \n",
            "21  | bert_decoder.encoder.layer.0.crossattention.self             | BertSelfAttention       | 197 K \n",
            "22  | bert_decoder.encoder.layer.0.crossattention.self.query       | Linear                  | 65 K  \n",
            "23  | bert_decoder.encoder.layer.0.crossattention.self.key         | Linear                  | 65 K  \n",
            "24  | bert_decoder.encoder.layer.0.crossattention.self.value       | Linear                  | 65 K  \n",
            "25  | bert_decoder.encoder.layer.0.crossattention.self.dropout     | Dropout                 | 0     \n",
            "26  | bert_decoder.encoder.layer.0.crossattention.output           | BertSelfOutput          | 66 K  \n",
            "27  | bert_decoder.encoder.layer.0.crossattention.output.dense     | Linear                  | 65 K  \n",
            "28  | bert_decoder.encoder.layer.0.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
            "29  | bert_decoder.encoder.layer.0.crossattention.output.dropout   | Dropout                 | 0     \n",
            "30  | bert_decoder.encoder.layer.0.intermediate                    | BertIntermediate        | 789 K \n",
            "31  | bert_decoder.encoder.layer.0.intermediate.dense              | Linear                  | 789 K \n",
            "32  | bert_decoder.encoder.layer.0.output                          | BertOutput              | 787 K \n",
            "33  | bert_decoder.encoder.layer.0.output.dense                    | Linear                  | 786 K \n",
            "34  | bert_decoder.encoder.layer.0.output.LayerNorm                | LayerNorm               | 512   \n",
            "35  | bert_decoder.encoder.layer.0.output.dropout                  | Dropout                 | 0     \n",
            "36  | bert_decoder.encoder.layer.1                                 | BertLayer               | 2 M   \n",
            "37  | bert_decoder.encoder.layer.1.attention                       | BertAttention           | 263 K \n",
            "38  | bert_decoder.encoder.layer.1.attention.self                  | BertSelfAttention       | 197 K \n",
            "39  | bert_decoder.encoder.layer.1.attention.self.query            | Linear                  | 65 K  \n",
            "40  | bert_decoder.encoder.layer.1.attention.self.key              | Linear                  | 65 K  \n",
            "41  | bert_decoder.encoder.layer.1.attention.self.value            | Linear                  | 65 K  \n",
            "42  | bert_decoder.encoder.layer.1.attention.self.dropout          | Dropout                 | 0     \n",
            "43  | bert_decoder.encoder.layer.1.attention.output                | BertSelfOutput          | 66 K  \n",
            "44  | bert_decoder.encoder.layer.1.attention.output.dense          | Linear                  | 65 K  \n",
            "45  | bert_decoder.encoder.layer.1.attention.output.LayerNorm      | LayerNorm               | 512   \n",
            "46  | bert_decoder.encoder.layer.1.attention.output.dropout        | Dropout                 | 0     \n",
            "47  | bert_decoder.encoder.layer.1.crossattention                  | BertAttention           | 263 K \n",
            "48  | bert_decoder.encoder.layer.1.crossattention.self             | BertSelfAttention       | 197 K \n",
            "49  | bert_decoder.encoder.layer.1.crossattention.self.query       | Linear                  | 65 K  \n",
            "50  | bert_decoder.encoder.layer.1.crossattention.self.key         | Linear                  | 65 K  \n",
            "51  | bert_decoder.encoder.layer.1.crossattention.self.value       | Linear                  | 65 K  \n",
            "52  | bert_decoder.encoder.layer.1.crossattention.self.dropout     | Dropout                 | 0     \n",
            "53  | bert_decoder.encoder.layer.1.crossattention.output           | BertSelfOutput          | 66 K  \n",
            "54  | bert_decoder.encoder.layer.1.crossattention.output.dense     | Linear                  | 65 K  \n",
            "55  | bert_decoder.encoder.layer.1.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
            "56  | bert_decoder.encoder.layer.1.crossattention.output.dropout   | Dropout                 | 0     \n",
            "57  | bert_decoder.encoder.layer.1.intermediate                    | BertIntermediate        | 789 K \n",
            "58  | bert_decoder.encoder.layer.1.intermediate.dense              | Linear                  | 789 K \n",
            "59  | bert_decoder.encoder.layer.1.output                          | BertOutput              | 787 K \n",
            "60  | bert_decoder.encoder.layer.1.output.dense                    | Linear                  | 786 K \n",
            "61  | bert_decoder.encoder.layer.1.output.LayerNorm                | LayerNorm               | 512   \n",
            "62  | bert_decoder.encoder.layer.1.output.dropout                  | Dropout                 | 0     \n",
            "63  | bert_decoder.encoder.layer.2                                 | BertLayer               | 2 M   \n",
            "64  | bert_decoder.encoder.layer.2.attention                       | BertAttention           | 263 K \n",
            "65  | bert_decoder.encoder.layer.2.attention.self                  | BertSelfAttention       | 197 K \n",
            "66  | bert_decoder.encoder.layer.2.attention.self.query            | Linear                  | 65 K  \n",
            "67  | bert_decoder.encoder.layer.2.attention.self.key              | Linear                  | 65 K  \n",
            "68  | bert_decoder.encoder.layer.2.attention.self.value            | Linear                  | 65 K  \n",
            "69  | bert_decoder.encoder.layer.2.attention.self.dropout          | Dropout                 | 0     \n",
            "70  | bert_decoder.encoder.layer.2.attention.output                | BertSelfOutput          | 66 K  \n",
            "71  | bert_decoder.encoder.layer.2.attention.output.dense          | Linear                  | 65 K  \n",
            "72  | bert_decoder.encoder.layer.2.attention.output.LayerNorm      | LayerNorm               | 512   \n",
            "73  | bert_decoder.encoder.layer.2.attention.output.dropout        | Dropout                 | 0     \n",
            "74  | bert_decoder.encoder.layer.2.crossattention                  | BertAttention           | 263 K \n",
            "75  | bert_decoder.encoder.layer.2.crossattention.self             | BertSelfAttention       | 197 K \n",
            "76  | bert_decoder.encoder.layer.2.crossattention.self.query       | Linear                  | 65 K  \n",
            "77  | bert_decoder.encoder.layer.2.crossattention.self.key         | Linear                  | 65 K  \n",
            "78  | bert_decoder.encoder.layer.2.crossattention.self.value       | Linear                  | 65 K  \n",
            "79  | bert_decoder.encoder.layer.2.crossattention.self.dropout     | Dropout                 | 0     \n",
            "80  | bert_decoder.encoder.layer.2.crossattention.output           | BertSelfOutput          | 66 K  \n",
            "81  | bert_decoder.encoder.layer.2.crossattention.output.dense     | Linear                  | 65 K  \n",
            "82  | bert_decoder.encoder.layer.2.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
            "83  | bert_decoder.encoder.layer.2.crossattention.output.dropout   | Dropout                 | 0     \n",
            "84  | bert_decoder.encoder.layer.2.intermediate                    | BertIntermediate        | 789 K \n",
            "85  | bert_decoder.encoder.layer.2.intermediate.dense              | Linear                  | 789 K \n",
            "86  | bert_decoder.encoder.layer.2.output                          | BertOutput              | 787 K \n",
            "87  | bert_decoder.encoder.layer.2.output.dense                    | Linear                  | 786 K \n",
            "88  | bert_decoder.encoder.layer.2.output.LayerNorm                | LayerNorm               | 512   \n",
            "89  | bert_decoder.encoder.layer.2.output.dropout                  | Dropout                 | 0     \n",
            "90  | bert_decoder.encoder.layer.3                                 | BertLayer               | 2 M   \n",
            "91  | bert_decoder.encoder.layer.3.attention                       | BertAttention           | 263 K \n",
            "92  | bert_decoder.encoder.layer.3.attention.self                  | BertSelfAttention       | 197 K \n",
            "93  | bert_decoder.encoder.layer.3.attention.self.query            | Linear                  | 65 K  \n",
            "94  | bert_decoder.encoder.layer.3.attention.self.key              | Linear                  | 65 K  \n",
            "95  | bert_decoder.encoder.layer.3.attention.self.value            | Linear                  | 65 K  \n",
            "96  | bert_decoder.encoder.layer.3.attention.self.dropout          | Dropout                 | 0     \n",
            "97  | bert_decoder.encoder.layer.3.attention.output                | BertSelfOutput          | 66 K  \n",
            "98  | bert_decoder.encoder.layer.3.attention.output.dense          | Linear                  | 65 K  \n",
            "99  | bert_decoder.encoder.layer.3.attention.output.LayerNorm      | LayerNorm               | 512   \n",
            "100 | bert_decoder.encoder.layer.3.attention.output.dropout        | Dropout                 | 0     \n",
            "101 | bert_decoder.encoder.layer.3.crossattention                  | BertAttention           | 263 K \n",
            "102 | bert_decoder.encoder.layer.3.crossattention.self             | BertSelfAttention       | 197 K \n",
            "103 | bert_decoder.encoder.layer.3.crossattention.self.query       | Linear                  | 65 K  \n",
            "104 | bert_decoder.encoder.layer.3.crossattention.self.key         | Linear                  | 65 K  \n",
            "105 | bert_decoder.encoder.layer.3.crossattention.self.value       | Linear                  | 65 K  \n",
            "106 | bert_decoder.encoder.layer.3.crossattention.self.dropout     | Dropout                 | 0     \n",
            "107 | bert_decoder.encoder.layer.3.crossattention.output           | BertSelfOutput          | 66 K  \n",
            "108 | bert_decoder.encoder.layer.3.crossattention.output.dense     | Linear                  | 65 K  \n",
            "109 | bert_decoder.encoder.layer.3.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
            "110 | bert_decoder.encoder.layer.3.crossattention.output.dropout   | Dropout                 | 0     \n",
            "111 | bert_decoder.encoder.layer.3.intermediate                    | BertIntermediate        | 789 K \n",
            "112 | bert_decoder.encoder.layer.3.intermediate.dense              | Linear                  | 789 K \n",
            "113 | bert_decoder.encoder.layer.3.output                          | BertOutput              | 787 K \n",
            "114 | bert_decoder.encoder.layer.3.output.dense                    | Linear                  | 786 K \n",
            "115 | bert_decoder.encoder.layer.3.output.LayerNorm                | LayerNorm               | 512   \n",
            "116 | bert_decoder.encoder.layer.3.output.dropout                  | Dropout                 | 0     \n",
            "117 | bert_decoder.encoder.layer.4                                 | BertLayer               | 2 M   \n",
            "118 | bert_decoder.encoder.layer.4.attention                       | BertAttention           | 263 K \n",
            "119 | bert_decoder.encoder.layer.4.attention.self                  | BertSelfAttention       | 197 K \n",
            "120 | bert_decoder.encoder.layer.4.attention.self.query            | Linear                  | 65 K  \n",
            "121 | bert_decoder.encoder.layer.4.attention.self.key              | Linear                  | 65 K  \n",
            "122 | bert_decoder.encoder.layer.4.attention.self.value            | Linear                  | 65 K  \n",
            "123 | bert_decoder.encoder.layer.4.attention.self.dropout          | Dropout                 | 0     \n",
            "124 | bert_decoder.encoder.layer.4.attention.output                | BertSelfOutput          | 66 K  \n",
            "125 | bert_decoder.encoder.layer.4.attention.output.dense          | Linear                  | 65 K  \n",
            "126 | bert_decoder.encoder.layer.4.attention.output.LayerNorm      | LayerNorm               | 512   \n",
            "127 | bert_decoder.encoder.layer.4.attention.output.dropout        | Dropout                 | 0     \n",
            "128 | bert_decoder.encoder.layer.4.crossattention                  | BertAttention           | 263 K \n",
            "129 | bert_decoder.encoder.layer.4.crossattention.self             | BertSelfAttention       | 197 K \n",
            "130 | bert_decoder.encoder.layer.4.crossattention.self.query       | Linear                  | 65 K  \n",
            "131 | bert_decoder.encoder.layer.4.crossattention.self.key         | Linear                  | 65 K  \n",
            "132 | bert_decoder.encoder.layer.4.crossattention.self.value       | Linear                  | 65 K  \n",
            "133 | bert_decoder.encoder.layer.4.crossattention.self.dropout     | Dropout                 | 0     \n",
            "134 | bert_decoder.encoder.layer.4.crossattention.output           | BertSelfOutput          | 66 K  \n",
            "135 | bert_decoder.encoder.layer.4.crossattention.output.dense     | Linear                  | 65 K  \n",
            "136 | bert_decoder.encoder.layer.4.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
            "137 | bert_decoder.encoder.layer.4.crossattention.output.dropout   | Dropout                 | 0     \n",
            "138 | bert_decoder.encoder.layer.4.intermediate                    | BertIntermediate        | 789 K \n",
            "139 | bert_decoder.encoder.layer.4.intermediate.dense              | Linear                  | 789 K \n",
            "140 | bert_decoder.encoder.layer.4.output                          | BertOutput              | 787 K \n",
            "141 | bert_decoder.encoder.layer.4.output.dense                    | Linear                  | 786 K \n",
            "142 | bert_decoder.encoder.layer.4.output.LayerNorm                | LayerNorm               | 512   \n",
            "143 | bert_decoder.encoder.layer.4.output.dropout                  | Dropout                 | 0     \n",
            "144 | bert_decoder.encoder.layer.5                                 | BertLayer               | 2 M   \n",
            "145 | bert_decoder.encoder.layer.5.attention                       | BertAttention           | 263 K \n",
            "146 | bert_decoder.encoder.layer.5.attention.self                  | BertSelfAttention       | 197 K \n",
            "147 | bert_decoder.encoder.layer.5.attention.self.query            | Linear                  | 65 K  \n",
            "148 | bert_decoder.encoder.layer.5.attention.self.key              | Linear                  | 65 K  \n",
            "149 | bert_decoder.encoder.layer.5.attention.self.value            | Linear                  | 65 K  \n",
            "150 | bert_decoder.encoder.layer.5.attention.self.dropout          | Dropout                 | 0     \n",
            "151 | bert_decoder.encoder.layer.5.attention.output                | BertSelfOutput          | 66 K  \n",
            "152 | bert_decoder.encoder.layer.5.attention.output.dense          | Linear                  | 65 K  \n",
            "153 | bert_decoder.encoder.layer.5.attention.output.LayerNorm      | LayerNorm               | 512   \n",
            "154 | bert_decoder.encoder.layer.5.attention.output.dropout        | Dropout                 | 0     \n",
            "155 | bert_decoder.encoder.layer.5.crossattention                  | BertAttention           | 263 K \n",
            "156 | bert_decoder.encoder.layer.5.crossattention.self             | BertSelfAttention       | 197 K \n",
            "157 | bert_decoder.encoder.layer.5.crossattention.self.query       | Linear                  | 65 K  \n",
            "158 | bert_decoder.encoder.layer.5.crossattention.self.key         | Linear                  | 65 K  \n",
            "159 | bert_decoder.encoder.layer.5.crossattention.self.value       | Linear                  | 65 K  \n",
            "160 | bert_decoder.encoder.layer.5.crossattention.self.dropout     | Dropout                 | 0     \n",
            "161 | bert_decoder.encoder.layer.5.crossattention.output           | BertSelfOutput          | 66 K  \n",
            "162 | bert_decoder.encoder.layer.5.crossattention.output.dense     | Linear                  | 65 K  \n",
            "163 | bert_decoder.encoder.layer.5.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
            "164 | bert_decoder.encoder.layer.5.crossattention.output.dropout   | Dropout                 | 0     \n",
            "165 | bert_decoder.encoder.layer.5.intermediate                    | BertIntermediate        | 789 K \n",
            "166 | bert_decoder.encoder.layer.5.intermediate.dense              | Linear                  | 789 K \n",
            "167 | bert_decoder.encoder.layer.5.output                          | BertOutput              | 787 K \n",
            "168 | bert_decoder.encoder.layer.5.output.dense                    | Linear                  | 786 K \n",
            "169 | bert_decoder.encoder.layer.5.output.LayerNorm                | LayerNorm               | 512   \n",
            "170 | bert_decoder.encoder.layer.5.output.dropout                  | Dropout                 | 0     \n",
            "171 | bert_decoder.pooler                                          | BertPooler              | 65 K  \n",
            "172 | bert_decoder.pooler.dense                                    | Linear                  | 65 K  \n",
            "173 | bert_decoder.pooler.activation                               | Tanh                    | 0     \n",
            "174 | detr                                                         | DETRdemo                | 41 M  \n",
            "175 | detr.backbone                                                | ResNet                  | 23 M  \n",
            "176 | detr.backbone.conv1                                          | Conv2d                  | 9 K   \n",
            "177 | detr.backbone.bn1                                            | BatchNorm2d             | 128   \n",
            "178 | detr.backbone.relu                                           | ReLU                    | 0     \n",
            "179 | detr.backbone.maxpool                                        | MaxPool2d               | 0     \n",
            "180 | detr.backbone.layer1                                         | Sequential              | 215 K \n",
            "181 | detr.backbone.layer1.0                                       | Bottleneck              | 75 K  \n",
            "182 | detr.backbone.layer1.0.conv1                                 | Conv2d                  | 4 K   \n",
            "183 | detr.backbone.layer1.0.bn1                                   | BatchNorm2d             | 128   \n",
            "184 | detr.backbone.layer1.0.conv2                                 | Conv2d                  | 36 K  \n",
            "185 | detr.backbone.layer1.0.bn2                                   | BatchNorm2d             | 128   \n",
            "186 | detr.backbone.layer1.0.conv3                                 | Conv2d                  | 16 K  \n",
            "187 | detr.backbone.layer1.0.bn3                                   | BatchNorm2d             | 512   \n",
            "188 | detr.backbone.layer1.0.relu                                  | ReLU                    | 0     \n",
            "189 | detr.backbone.layer1.0.downsample                            | Sequential              | 16 K  \n",
            "190 | detr.backbone.layer1.0.downsample.0                          | Conv2d                  | 16 K  \n",
            "191 | detr.backbone.layer1.0.downsample.1                          | BatchNorm2d             | 512   \n",
            "192 | detr.backbone.layer1.1                                       | Bottleneck              | 70 K  \n",
            "193 | detr.backbone.layer1.1.conv1                                 | Conv2d                  | 16 K  \n",
            "194 | detr.backbone.layer1.1.bn1                                   | BatchNorm2d             | 128   \n",
            "195 | detr.backbone.layer1.1.conv2                                 | Conv2d                  | 36 K  \n",
            "196 | detr.backbone.layer1.1.bn2                                   | BatchNorm2d             | 128   \n",
            "197 | detr.backbone.layer1.1.conv3                                 | Conv2d                  | 16 K  \n",
            "198 | detr.backbone.layer1.1.bn3                                   | BatchNorm2d             | 512   \n",
            "199 | detr.backbone.layer1.1.relu                                  | ReLU                    | 0     \n",
            "200 | detr.backbone.layer1.2                                       | Bottleneck              | 70 K  \n",
            "201 | detr.backbone.layer1.2.conv1                                 | Conv2d                  | 16 K  \n",
            "202 | detr.backbone.layer1.2.bn1                                   | BatchNorm2d             | 128   \n",
            "203 | detr.backbone.layer1.2.conv2                                 | Conv2d                  | 36 K  \n",
            "204 | detr.backbone.layer1.2.bn2                                   | BatchNorm2d             | 128   \n",
            "205 | detr.backbone.layer1.2.conv3                                 | Conv2d                  | 16 K  \n",
            "206 | detr.backbone.layer1.2.bn3                                   | BatchNorm2d             | 512   \n",
            "207 | detr.backbone.layer1.2.relu                                  | ReLU                    | 0     \n",
            "208 | detr.backbone.layer2                                         | Sequential              | 1 M   \n",
            "209 | detr.backbone.layer2.0                                       | Bottleneck              | 379 K \n",
            "210 | detr.backbone.layer2.0.conv1                                 | Conv2d                  | 32 K  \n",
            "211 | detr.backbone.layer2.0.bn1                                   | BatchNorm2d             | 256   \n",
            "212 | detr.backbone.layer2.0.conv2                                 | Conv2d                  | 147 K \n",
            "213 | detr.backbone.layer2.0.bn2                                   | BatchNorm2d             | 256   \n",
            "214 | detr.backbone.layer2.0.conv3                                 | Conv2d                  | 65 K  \n",
            "215 | detr.backbone.layer2.0.bn3                                   | BatchNorm2d             | 1 K   \n",
            "216 | detr.backbone.layer2.0.relu                                  | ReLU                    | 0     \n",
            "217 | detr.backbone.layer2.0.downsample                            | Sequential              | 132 K \n",
            "218 | detr.backbone.layer2.0.downsample.0                          | Conv2d                  | 131 K \n",
            "219 | detr.backbone.layer2.0.downsample.1                          | BatchNorm2d             | 1 K   \n",
            "220 | detr.backbone.layer2.1                                       | Bottleneck              | 280 K \n",
            "221 | detr.backbone.layer2.1.conv1                                 | Conv2d                  | 65 K  \n",
            "222 | detr.backbone.layer2.1.bn1                                   | BatchNorm2d             | 256   \n",
            "223 | detr.backbone.layer2.1.conv2                                 | Conv2d                  | 147 K \n",
            "224 | detr.backbone.layer2.1.bn2                                   | BatchNorm2d             | 256   \n",
            "225 | detr.backbone.layer2.1.conv3                                 | Conv2d                  | 65 K  \n",
            "226 | detr.backbone.layer2.1.bn3                                   | BatchNorm2d             | 1 K   \n",
            "227 | detr.backbone.layer2.1.relu                                  | ReLU                    | 0     \n",
            "228 | detr.backbone.layer2.2                                       | Bottleneck              | 280 K \n",
            "229 | detr.backbone.layer2.2.conv1                                 | Conv2d                  | 65 K  \n",
            "230 | detr.backbone.layer2.2.bn1                                   | BatchNorm2d             | 256   \n",
            "231 | detr.backbone.layer2.2.conv2                                 | Conv2d                  | 147 K \n",
            "232 | detr.backbone.layer2.2.bn2                                   | BatchNorm2d             | 256   \n",
            "233 | detr.backbone.layer2.2.conv3                                 | Conv2d                  | 65 K  \n",
            "234 | detr.backbone.layer2.2.bn3                                   | BatchNorm2d             | 1 K   \n",
            "235 | detr.backbone.layer2.2.relu                                  | ReLU                    | 0     \n",
            "236 | detr.backbone.layer2.3                                       | Bottleneck              | 280 K \n",
            "237 | detr.backbone.layer2.3.conv1                                 | Conv2d                  | 65 K  \n",
            "238 | detr.backbone.layer2.3.bn1                                   | BatchNorm2d             | 256   \n",
            "239 | detr.backbone.layer2.3.conv2                                 | Conv2d                  | 147 K \n",
            "240 | detr.backbone.layer2.3.bn2                                   | BatchNorm2d             | 256   \n",
            "241 | detr.backbone.layer2.3.conv3                                 | Conv2d                  | 65 K  \n",
            "242 | detr.backbone.layer2.3.bn3                                   | BatchNorm2d             | 1 K   \n",
            "243 | detr.backbone.layer2.3.relu                                  | ReLU                    | 0     \n",
            "244 | detr.backbone.layer3                                         | Sequential              | 7 M   \n",
            "245 | detr.backbone.layer3.0                                       | Bottleneck              | 1 M   \n",
            "246 | detr.backbone.layer3.0.conv1                                 | Conv2d                  | 131 K \n",
            "247 | detr.backbone.layer3.0.bn1                                   | BatchNorm2d             | 512   \n",
            "248 | detr.backbone.layer3.0.conv2                                 | Conv2d                  | 589 K \n",
            "249 | detr.backbone.layer3.0.bn2                                   | BatchNorm2d             | 512   \n",
            "250 | detr.backbone.layer3.0.conv3                                 | Conv2d                  | 262 K \n",
            "251 | detr.backbone.layer3.0.bn3                                   | BatchNorm2d             | 2 K   \n",
            "252 | detr.backbone.layer3.0.relu                                  | ReLU                    | 0     \n",
            "253 | detr.backbone.layer3.0.downsample                            | Sequential              | 526 K \n",
            "254 | detr.backbone.layer3.0.downsample.0                          | Conv2d                  | 524 K \n",
            "255 | detr.backbone.layer3.0.downsample.1                          | BatchNorm2d             | 2 K   \n",
            "256 | detr.backbone.layer3.1                                       | Bottleneck              | 1 M   \n",
            "257 | detr.backbone.layer3.1.conv1                                 | Conv2d                  | 262 K \n",
            "258 | detr.backbone.layer3.1.bn1                                   | BatchNorm2d             | 512   \n",
            "259 | detr.backbone.layer3.1.conv2                                 | Conv2d                  | 589 K \n",
            "260 | detr.backbone.layer3.1.bn2                                   | BatchNorm2d             | 512   \n",
            "261 | detr.backbone.layer3.1.conv3                                 | Conv2d                  | 262 K \n",
            "262 | detr.backbone.layer3.1.bn3                                   | BatchNorm2d             | 2 K   \n",
            "263 | detr.backbone.layer3.1.relu                                  | ReLU                    | 0     \n",
            "264 | detr.backbone.layer3.2                                       | Bottleneck              | 1 M   \n",
            "265 | detr.backbone.layer3.2.conv1                                 | Conv2d                  | 262 K \n",
            "266 | detr.backbone.layer3.2.bn1                                   | BatchNorm2d             | 512   \n",
            "267 | detr.backbone.layer3.2.conv2                                 | Conv2d                  | 589 K \n",
            "268 | detr.backbone.layer3.2.bn2                                   | BatchNorm2d             | 512   \n",
            "269 | detr.backbone.layer3.2.conv3                                 | Conv2d                  | 262 K \n",
            "270 | detr.backbone.layer3.2.bn3                                   | BatchNorm2d             | 2 K   \n",
            "271 | detr.backbone.layer3.2.relu                                  | ReLU                    | 0     \n",
            "272 | detr.backbone.layer3.3                                       | Bottleneck              | 1 M   \n",
            "273 | detr.backbone.layer3.3.conv1                                 | Conv2d                  | 262 K \n",
            "274 | detr.backbone.layer3.3.bn1                                   | BatchNorm2d             | 512   \n",
            "275 | detr.backbone.layer3.3.conv2                                 | Conv2d                  | 589 K \n",
            "276 | detr.backbone.layer3.3.bn2                                   | BatchNorm2d             | 512   \n",
            "277 | detr.backbone.layer3.3.conv3                                 | Conv2d                  | 262 K \n",
            "278 | detr.backbone.layer3.3.bn3                                   | BatchNorm2d             | 2 K   \n",
            "279 | detr.backbone.layer3.3.relu                                  | ReLU                    | 0     \n",
            "280 | detr.backbone.layer3.4                                       | Bottleneck              | 1 M   \n",
            "281 | detr.backbone.layer3.4.conv1                                 | Conv2d                  | 262 K \n",
            "282 | detr.backbone.layer3.4.bn1                                   | BatchNorm2d             | 512   \n",
            "283 | detr.backbone.layer3.4.conv2                                 | Conv2d                  | 589 K \n",
            "284 | detr.backbone.layer3.4.bn2                                   | BatchNorm2d             | 512   \n",
            "285 | detr.backbone.layer3.4.conv3                                 | Conv2d                  | 262 K \n",
            "286 | detr.backbone.layer3.4.bn3                                   | BatchNorm2d             | 2 K   \n",
            "287 | detr.backbone.layer3.4.relu                                  | ReLU                    | 0     \n",
            "288 | detr.backbone.layer3.5                                       | Bottleneck              | 1 M   \n",
            "289 | detr.backbone.layer3.5.conv1                                 | Conv2d                  | 262 K \n",
            "290 | detr.backbone.layer3.5.bn1                                   | BatchNorm2d             | 512   \n",
            "291 | detr.backbone.layer3.5.conv2                                 | Conv2d                  | 589 K \n",
            "292 | detr.backbone.layer3.5.bn2                                   | BatchNorm2d             | 512   \n",
            "293 | detr.backbone.layer3.5.conv3                                 | Conv2d                  | 262 K \n",
            "294 | detr.backbone.layer3.5.bn3                                   | BatchNorm2d             | 2 K   \n",
            "295 | detr.backbone.layer3.5.relu                                  | ReLU                    | 0     \n",
            "296 | detr.backbone.layer4                                         | Sequential              | 14 M  \n",
            "297 | detr.backbone.layer4.0                                       | Bottleneck              | 6 M   \n",
            "298 | detr.backbone.layer4.0.conv1                                 | Conv2d                  | 524 K \n",
            "299 | detr.backbone.layer4.0.bn1                                   | BatchNorm2d             | 1 K   \n",
            "300 | detr.backbone.layer4.0.conv2                                 | Conv2d                  | 2 M   \n",
            "301 | detr.backbone.layer4.0.bn2                                   | BatchNorm2d             | 1 K   \n",
            "302 | detr.backbone.layer4.0.conv3                                 | Conv2d                  | 1 M   \n",
            "303 | detr.backbone.layer4.0.bn3                                   | BatchNorm2d             | 4 K   \n",
            "304 | detr.backbone.layer4.0.relu                                  | ReLU                    | 0     \n",
            "305 | detr.backbone.layer4.0.downsample                            | Sequential              | 2 M   \n",
            "306 | detr.backbone.layer4.0.downsample.0                          | Conv2d                  | 2 M   \n",
            "307 | detr.backbone.layer4.0.downsample.1                          | BatchNorm2d             | 4 K   \n",
            "308 | detr.backbone.layer4.1                                       | Bottleneck              | 4 M   \n",
            "309 | detr.backbone.layer4.1.conv1                                 | Conv2d                  | 1 M   \n",
            "310 | detr.backbone.layer4.1.bn1                                   | BatchNorm2d             | 1 K   \n",
            "311 | detr.backbone.layer4.1.conv2                                 | Conv2d                  | 2 M   \n",
            "312 | detr.backbone.layer4.1.bn2                                   | BatchNorm2d             | 1 K   \n",
            "313 | detr.backbone.layer4.1.conv3                                 | Conv2d                  | 1 M   \n",
            "314 | detr.backbone.layer4.1.bn3                                   | BatchNorm2d             | 4 K   \n",
            "315 | detr.backbone.layer4.1.relu                                  | ReLU                    | 0     \n",
            "316 | detr.backbone.layer4.2                                       | Bottleneck              | 4 M   \n",
            "317 | detr.backbone.layer4.2.conv1                                 | Conv2d                  | 1 M   \n",
            "318 | detr.backbone.layer4.2.bn1                                   | BatchNorm2d             | 1 K   \n",
            "319 | detr.backbone.layer4.2.conv2                                 | Conv2d                  | 2 M   \n",
            "320 | detr.backbone.layer4.2.bn2                                   | BatchNorm2d             | 1 K   \n",
            "321 | detr.backbone.layer4.2.conv3                                 | Conv2d                  | 1 M   \n",
            "322 | detr.backbone.layer4.2.bn3                                   | BatchNorm2d             | 4 K   \n",
            "323 | detr.backbone.layer4.2.relu                                  | ReLU                    | 0     \n",
            "324 | detr.backbone.avgpool                                        | AdaptiveAvgPool2d       | 0     \n",
            "325 | detr.conv                                                    | Conv2d                  | 524 K \n",
            "326 | detr.transformer                                             | Transformer             | 17 M  \n",
            "327 | detr.transformer.encoder                                     | TransformerEncoder      | 7 M   \n",
            "328 | detr.transformer.encoder.layers                              | ModuleList              | 7 M   \n",
            "329 | detr.transformer.encoder.layers.0                            | TransformerEncoderLayer | 1 M   \n",
            "330 | detr.transformer.encoder.layers.0.self_attn                  | MultiheadAttention      | 263 K \n",
            "331 | detr.transformer.encoder.layers.0.self_attn.out_proj         | Linear                  | 65 K  \n",
            "332 | detr.transformer.encoder.layers.0.linear1                    | Linear                  | 526 K \n",
            "333 | detr.transformer.encoder.layers.0.dropout                    | Dropout                 | 0     \n",
            "334 | detr.transformer.encoder.layers.0.linear2                    | Linear                  | 524 K \n",
            "335 | detr.transformer.encoder.layers.0.norm1                      | LayerNorm               | 512   \n",
            "336 | detr.transformer.encoder.layers.0.norm2                      | LayerNorm               | 512   \n",
            "337 | detr.transformer.encoder.layers.0.dropout1                   | Dropout                 | 0     \n",
            "338 | detr.transformer.encoder.layers.0.dropout2                   | Dropout                 | 0     \n",
            "339 | detr.transformer.encoder.layers.1                            | TransformerEncoderLayer | 1 M   \n",
            "340 | detr.transformer.encoder.layers.1.self_attn                  | MultiheadAttention      | 263 K \n",
            "341 | detr.transformer.encoder.layers.1.self_attn.out_proj         | Linear                  | 65 K  \n",
            "342 | detr.transformer.encoder.layers.1.linear1                    | Linear                  | 526 K \n",
            "343 | detr.transformer.encoder.layers.1.dropout                    | Dropout                 | 0     \n",
            "344 | detr.transformer.encoder.layers.1.linear2                    | Linear                  | 524 K \n",
            "345 | detr.transformer.encoder.layers.1.norm1                      | LayerNorm               | 512   \n",
            "346 | detr.transformer.encoder.layers.1.norm2                      | LayerNorm               | 512   \n",
            "347 | detr.transformer.encoder.layers.1.dropout1                   | Dropout                 | 0     \n",
            "348 | detr.transformer.encoder.layers.1.dropout2                   | Dropout                 | 0     \n",
            "349 | detr.transformer.encoder.layers.2                            | TransformerEncoderLayer | 1 M   \n",
            "350 | detr.transformer.encoder.layers.2.self_attn                  | MultiheadAttention      | 263 K \n",
            "351 | detr.transformer.encoder.layers.2.self_attn.out_proj         | Linear                  | 65 K  \n",
            "352 | detr.transformer.encoder.layers.2.linear1                    | Linear                  | 526 K \n",
            "353 | detr.transformer.encoder.layers.2.dropout                    | Dropout                 | 0     \n",
            "354 | detr.transformer.encoder.layers.2.linear2                    | Linear                  | 524 K \n",
            "355 | detr.transformer.encoder.layers.2.norm1                      | LayerNorm               | 512   \n",
            "356 | detr.transformer.encoder.layers.2.norm2                      | LayerNorm               | 512   \n",
            "357 | detr.transformer.encoder.layers.2.dropout1                   | Dropout                 | 0     \n",
            "358 | detr.transformer.encoder.layers.2.dropout2                   | Dropout                 | 0     \n",
            "359 | detr.transformer.encoder.layers.3                            | TransformerEncoderLayer | 1 M   \n",
            "360 | detr.transformer.encoder.layers.3.self_attn                  | MultiheadAttention      | 263 K \n",
            "361 | detr.transformer.encoder.layers.3.self_attn.out_proj         | Linear                  | 65 K  \n",
            "362 | detr.transformer.encoder.layers.3.linear1                    | Linear                  | 526 K \n",
            "363 | detr.transformer.encoder.layers.3.dropout                    | Dropout                 | 0     \n",
            "364 | detr.transformer.encoder.layers.3.linear2                    | Linear                  | 524 K \n",
            "365 | detr.transformer.encoder.layers.3.norm1                      | LayerNorm               | 512   \n",
            "366 | detr.transformer.encoder.layers.3.norm2                      | LayerNorm               | 512   \n",
            "367 | detr.transformer.encoder.layers.3.dropout1                   | Dropout                 | 0     \n",
            "368 | detr.transformer.encoder.layers.3.dropout2                   | Dropout                 | 0     \n",
            "369 | detr.transformer.encoder.layers.4                            | TransformerEncoderLayer | 1 M   \n",
            "370 | detr.transformer.encoder.layers.4.self_attn                  | MultiheadAttention      | 263 K \n",
            "371 | detr.transformer.encoder.layers.4.self_attn.out_proj         | Linear                  | 65 K  \n",
            "372 | detr.transformer.encoder.layers.4.linear1                    | Linear                  | 526 K \n",
            "373 | detr.transformer.encoder.layers.4.dropout                    | Dropout                 | 0     \n",
            "374 | detr.transformer.encoder.layers.4.linear2                    | Linear                  | 524 K \n",
            "375 | detr.transformer.encoder.layers.4.norm1                      | LayerNorm               | 512   \n",
            "376 | detr.transformer.encoder.layers.4.norm2                      | LayerNorm               | 512   \n",
            "377 | detr.transformer.encoder.layers.4.dropout1                   | Dropout                 | 0     \n",
            "378 | detr.transformer.encoder.layers.4.dropout2                   | Dropout                 | 0     \n",
            "379 | detr.transformer.encoder.layers.5                            | TransformerEncoderLayer | 1 M   \n",
            "380 | detr.transformer.encoder.layers.5.self_attn                  | MultiheadAttention      | 263 K \n",
            "381 | detr.transformer.encoder.layers.5.self_attn.out_proj         | Linear                  | 65 K  \n",
            "382 | detr.transformer.encoder.layers.5.linear1                    | Linear                  | 526 K \n",
            "383 | detr.transformer.encoder.layers.5.dropout                    | Dropout                 | 0     \n",
            "384 | detr.transformer.encoder.layers.5.linear2                    | Linear                  | 524 K \n",
            "385 | detr.transformer.encoder.layers.5.norm1                      | LayerNorm               | 512   \n",
            "386 | detr.transformer.encoder.layers.5.norm2                      | LayerNorm               | 512   \n",
            "387 | detr.transformer.encoder.layers.5.dropout1                   | Dropout                 | 0     \n",
            "388 | detr.transformer.encoder.layers.5.dropout2                   | Dropout                 | 0     \n",
            "389 | detr.transformer.encoder.norm                                | LayerNorm               | 512   \n",
            "390 | detr.transformer.decoder                                     | TransformerDecoder      | 9 M   \n",
            "391 | detr.transformer.decoder.layers                              | ModuleList              | 9 M   \n",
            "392 | detr.transformer.decoder.layers.0                            | TransformerDecoderLayer | 1 M   \n",
            "393 | detr.transformer.decoder.layers.0.self_attn                  | MultiheadAttention      | 263 K \n",
            "394 | detr.transformer.decoder.layers.0.self_attn.out_proj         | Linear                  | 65 K  \n",
            "395 | detr.transformer.decoder.layers.0.multihead_attn             | MultiheadAttention      | 263 K \n",
            "396 | detr.transformer.decoder.layers.0.multihead_attn.out_proj    | Linear                  | 65 K  \n",
            "397 | detr.transformer.decoder.layers.0.linear1                    | Linear                  | 526 K \n",
            "398 | detr.transformer.decoder.layers.0.dropout                    | Dropout                 | 0     \n",
            "399 | detr.transformer.decoder.layers.0.linear2                    | Linear                  | 524 K \n",
            "400 | detr.transformer.decoder.layers.0.norm1                      | LayerNorm               | 512   \n",
            "401 | detr.transformer.decoder.layers.0.norm2                      | LayerNorm               | 512   \n",
            "402 | detr.transformer.decoder.layers.0.norm3                      | LayerNorm               | 512   \n",
            "403 | detr.transformer.decoder.layers.0.dropout1                   | Dropout                 | 0     \n",
            "404 | detr.transformer.decoder.layers.0.dropout2                   | Dropout                 | 0     \n",
            "405 | detr.transformer.decoder.layers.0.dropout3                   | Dropout                 | 0     \n",
            "406 | detr.transformer.decoder.layers.1                            | TransformerDecoderLayer | 1 M   \n",
            "407 | detr.transformer.decoder.layers.1.self_attn                  | MultiheadAttention      | 263 K \n",
            "408 | detr.transformer.decoder.layers.1.self_attn.out_proj         | Linear                  | 65 K  \n",
            "409 | detr.transformer.decoder.layers.1.multihead_attn             | MultiheadAttention      | 263 K \n",
            "410 | detr.transformer.decoder.layers.1.multihead_attn.out_proj    | Linear                  | 65 K  \n",
            "411 | detr.transformer.decoder.layers.1.linear1                    | Linear                  | 526 K \n",
            "412 | detr.transformer.decoder.layers.1.dropout                    | Dropout                 | 0     \n",
            "413 | detr.transformer.decoder.layers.1.linear2                    | Linear                  | 524 K \n",
            "414 | detr.transformer.decoder.layers.1.norm1                      | LayerNorm               | 512   \n",
            "415 | detr.transformer.decoder.layers.1.norm2                      | LayerNorm               | 512   \n",
            "416 | detr.transformer.decoder.layers.1.norm3                      | LayerNorm               | 512   \n",
            "417 | detr.transformer.decoder.layers.1.dropout1                   | Dropout                 | 0     \n",
            "418 | detr.transformer.decoder.layers.1.dropout2                   | Dropout                 | 0     \n",
            "419 | detr.transformer.decoder.layers.1.dropout3                   | Dropout                 | 0     \n",
            "420 | detr.transformer.decoder.layers.2                            | TransformerDecoderLayer | 1 M   \n",
            "421 | detr.transformer.decoder.layers.2.self_attn                  | MultiheadAttention      | 263 K \n",
            "422 | detr.transformer.decoder.layers.2.self_attn.out_proj         | Linear                  | 65 K  \n",
            "423 | detr.transformer.decoder.layers.2.multihead_attn             | MultiheadAttention      | 263 K \n",
            "424 | detr.transformer.decoder.layers.2.multihead_attn.out_proj    | Linear                  | 65 K  \n",
            "425 | detr.transformer.decoder.layers.2.linear1                    | Linear                  | 526 K \n",
            "426 | detr.transformer.decoder.layers.2.dropout                    | Dropout                 | 0     \n",
            "427 | detr.transformer.decoder.layers.2.linear2                    | Linear                  | 524 K \n",
            "428 | detr.transformer.decoder.layers.2.norm1                      | LayerNorm               | 512   \n",
            "429 | detr.transformer.decoder.layers.2.norm2                      | LayerNorm               | 512   \n",
            "430 | detr.transformer.decoder.layers.2.norm3                      | LayerNorm               | 512   \n",
            "431 | detr.transformer.decoder.layers.2.dropout1                   | Dropout                 | 0     \n",
            "432 | detr.transformer.decoder.layers.2.dropout2                   | Dropout                 | 0     \n",
            "433 | detr.transformer.decoder.layers.2.dropout3                   | Dropout                 | 0     \n",
            "434 | detr.transformer.decoder.layers.3                            | TransformerDecoderLayer | 1 M   \n",
            "435 | detr.transformer.decoder.layers.3.self_attn                  | MultiheadAttention      | 263 K \n",
            "436 | detr.transformer.decoder.layers.3.self_attn.out_proj         | Linear                  | 65 K  \n",
            "437 | detr.transformer.decoder.layers.3.multihead_attn             | MultiheadAttention      | 263 K \n",
            "438 | detr.transformer.decoder.layers.3.multihead_attn.out_proj    | Linear                  | 65 K  \n",
            "439 | detr.transformer.decoder.layers.3.linear1                    | Linear                  | 526 K \n",
            "440 | detr.transformer.decoder.layers.3.dropout                    | Dropout                 | 0     \n",
            "441 | detr.transformer.decoder.layers.3.linear2                    | Linear                  | 524 K \n",
            "442 | detr.transformer.decoder.layers.3.norm1                      | LayerNorm               | 512   \n",
            "443 | detr.transformer.decoder.layers.3.norm2                      | LayerNorm               | 512   \n",
            "444 | detr.transformer.decoder.layers.3.norm3                      | LayerNorm               | 512   \n",
            "445 | detr.transformer.decoder.layers.3.dropout1                   | Dropout                 | 0     \n",
            "446 | detr.transformer.decoder.layers.3.dropout2                   | Dropout                 | 0     \n",
            "447 | detr.transformer.decoder.layers.3.dropout3                   | Dropout                 | 0     \n",
            "448 | detr.transformer.decoder.layers.4                            | TransformerDecoderLayer | 1 M   \n",
            "449 | detr.transformer.decoder.layers.4.self_attn                  | MultiheadAttention      | 263 K \n",
            "450 | detr.transformer.decoder.layers.4.self_attn.out_proj         | Linear                  | 65 K  \n",
            "451 | detr.transformer.decoder.layers.4.multihead_attn             | MultiheadAttention      | 263 K \n",
            "452 | detr.transformer.decoder.layers.4.multihead_attn.out_proj    | Linear                  | 65 K  \n",
            "453 | detr.transformer.decoder.layers.4.linear1                    | Linear                  | 526 K \n",
            "454 | detr.transformer.decoder.layers.4.dropout                    | Dropout                 | 0     \n",
            "455 | detr.transformer.decoder.layers.4.linear2                    | Linear                  | 524 K \n",
            "456 | detr.transformer.decoder.layers.4.norm1                      | LayerNorm               | 512   \n",
            "457 | detr.transformer.decoder.layers.4.norm2                      | LayerNorm               | 512   \n",
            "458 | detr.transformer.decoder.layers.4.norm3                      | LayerNorm               | 512   \n",
            "459 | detr.transformer.decoder.layers.4.dropout1                   | Dropout                 | 0     \n",
            "460 | detr.transformer.decoder.layers.4.dropout2                   | Dropout                 | 0     \n",
            "461 | detr.transformer.decoder.layers.4.dropout3                   | Dropout                 | 0     \n",
            "462 | detr.transformer.decoder.layers.5                            | TransformerDecoderLayer | 1 M   \n",
            "463 | detr.transformer.decoder.layers.5.self_attn                  | MultiheadAttention      | 263 K \n",
            "464 | detr.transformer.decoder.layers.5.self_attn.out_proj         | Linear                  | 65 K  \n",
            "465 | detr.transformer.decoder.layers.5.multihead_attn             | MultiheadAttention      | 263 K \n",
            "466 | detr.transformer.decoder.layers.5.multihead_attn.out_proj    | Linear                  | 65 K  \n",
            "467 | detr.transformer.decoder.layers.5.linear1                    | Linear                  | 526 K \n",
            "468 | detr.transformer.decoder.layers.5.dropout                    | Dropout                 | 0     \n",
            "469 | detr.transformer.decoder.layers.5.linear2                    | Linear                  | 524 K \n",
            "470 | detr.transformer.decoder.layers.5.norm1                      | LayerNorm               | 512   \n",
            "471 | detr.transformer.decoder.layers.5.norm2                      | LayerNorm               | 512   \n",
            "472 | detr.transformer.decoder.layers.5.norm3                      | LayerNorm               | 512   \n",
            "473 | detr.transformer.decoder.layers.5.dropout1                   | Dropout                 | 0     \n",
            "474 | detr.transformer.decoder.layers.5.dropout2                   | Dropout                 | 0     \n",
            "475 | detr.transformer.decoder.layers.5.dropout3                   | Dropout                 | 0     \n",
            "476 | detr.transformer.decoder.norm                                | LayerNorm               | 512   \n",
            "477 | detr.linear_class                                            | Linear                  | 23 K  \n",
            "478 | detr.linear_bbox                                             | Linear                  | 1 K   \n",
            "479 | classifier                                                   | Linear                  | 83 M  \n",
            "480 | drop_out                                                     | Dropout                 | 0     \n",
            "481 | log_softmax                                                  | LogSoftmax              | 0     \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abaaad1b05c24240b8d2088d5e2e443d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(427, 640)\n",
            "(427, 640, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6b7aec706f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tpu_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_save_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/gdrive/My Drive/dl_projects/VQA_detr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvqa_detr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tpu_cores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;31m# load weights if not interrupted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 raise Exception(\n\u001b[1;32m    107\u001b[0m                     \u001b[0;34m\"process %d terminated with signal %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                 )\n\u001b[1;32m    110\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: process 6 terminated with signal SIGKILL"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpsKfzoTPvN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "62c0de5b-adc0-4473-c2cd-7c75b0c3fe24"
      },
      "source": [
        "# Start tensorboard.\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir gdrive/My Drive/dl_projects/VQA_detr/lightning_logs/serve"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 2).\n",
              "Contents of stderr:\n",
              "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
              "                   [--host ADDR] [--bind_all] [--port PORT]\n",
              "                   [--purge_orphaned_data BOOL] [--db URI] [--db_import]\n",
              "                   [--inspect] [--version_tb] [--tag TAG] [--event_file PATH]\n",
              "                   [--path_prefix PATH] [--window_title TEXT]\n",
              "                   [--max_reload_threads COUNT] [--reload_interval SECONDS]\n",
              "                   [--reload_task TYPE] [--reload_multifile BOOL]\n",
              "                   [--reload_multifile_inactive_secs SECONDS]\n",
              "                   [--generic_data TYPE]\n",
              "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
              "                   [--debugger_data_server_grpc_port PORT]\n",
              "                   [--debugger_port PORT]\n",
              "                   {serve,dev} ...\n",
              "tensorboard: error: invalid choice: 'Drive/dl_projects/VQA_detr/lightning_logs/' (choose from 'serve', 'dev')"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkixu9cEiuH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save= model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmkzyZD2lms4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save.eval().to('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LocAAdSLiyoJ",
        "colab_type": "code",
        "outputId": "50de639e-6cec-4d69-964b-c612af188024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "img,q,a=vqa_data[4522]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0C9hbUzjA7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "out = model_save(img.unsqueeze(0),q['ids'].unsqueeze(0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p672z_Qvjh2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,index = out['logits'].max(dim = -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB5ULieHlM7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_tokenizer.convert_ids_to_tokens(q['ids'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bvtBHGVkDr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_answers[int(index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2RgCuljj0rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(img.permute(1,2,0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYwwjn7cg5LL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9ef34080-a2e3-49e7-f9d1-624b2b4bb4bf"
      },
      "source": [
        "while 1:\n",
        "    continue"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c9af83e2fc0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzGeoINdgUkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeUiwvNxg5IL",
        "colab_type": "code",
        "outputId": "d016ae3b-bdb4-43a4-feaf-f5e9b673f147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "output = loss(input, target)\n",
        "print(output)\n",
        "output.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.7195, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxWysSRHg5GM",
        "colab_type": "code",
        "outputId": "4597a5b0-57e0-48e6-9fd2-63346294fce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7E47VdQBYim",
        "colab_type": "code",
        "outputId": "740f2c14-14aa-4500-e039-bfda773c20a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "output.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kRrRu0Pg5CD",
        "colab_type": "code",
        "outputId": "fa93fa9f-f554-46bf-8eb9-2f037c22789a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = np.array([1, 2])\n",
        "print(x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB1c-xPkg4_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z=np.expand_dims(x, axis=-1)\n",
        "np.repeat(z,3,axis=-1).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC7x-7cgg48D",
        "colab_type": "code",
        "outputId": "eceb7049-1453-49c7-ab64-298391547a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMYEVVN6g46I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW4yYVKkg42L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN4YyXjspxbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for im,q,a in data_loader:\n",
        "    print(im.shape)\n",
        "    print(q['ids'].shape)\n",
        "    print(a.shape)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdEvUm4kDjvx",
        "colab_type": "code",
        "outputId": "5d64ecf0-9113-4ed4-884d-ab672c7a98ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(answer_to_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EX7BA0oNFVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img,q,a=vqa_data[58]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJExIYdDGwlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b=torch.max(a.unsqueeze(0),dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9ad7adt54T7",
        "colab_type": "code",
        "outputId": "44a748ef-865c-4ba6-d8a4-710325d74af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "b.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-f64918c89499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: only Tensors of floating point dtype can require gradients"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72e-rwiQNFLF",
        "colab_type": "code",
        "outputId": "fbe9d96a-5881-4e41-dc2a-12963ab48a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a.unsqueeze(0).view(-1,1).shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([162496, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0R64hJAnvC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_config = BertConfig(hidden_size=256, num_attention_heads=8, num_hidden_layers=6)\n",
        "bert_decoder_config = BertConfig(is_decoder=True, hidden_size=256, num_attention_heads=8, num_hidden_layers=6)\n",
        "\n",
        "enc_dec_config = EncoderDecoderConfig.from_encoder_decoder_configs(encoder_config= bert_config, decoder_config= bert_decoder_config)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcNZWDKPlRlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = EncoderDecoderModel(config= enc_dec_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfZOXxIFlZK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = model(input_ids = q['ids'].unsqueeze(0), decoder_inputs_embeds = h[0].unsqueeze(0).flatten(2).permute(2, 0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsjQtkw0mGv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs[2].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8H-1gtoRmWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_decoder = BertModel(config  = bert_decoder_config)\n",
        "outputs = bert_decoder(input_ids = q['ids'].unsqueeze(0), encoder_hidden_states = h[0].unsqueeze(0).flatten(2).permute(0,2,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fpRcCBhSe63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = bert_decoder(input_ids = q['ids'].unsqueeze(0), encoder_hidden_states = h[0].unsqueeze(0).flatten(2).permute(0,2,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6q0BavU9BHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while 1 :\n",
        "    continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-91LWQZDc1wK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BertModel??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlIue81hy08k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " h[0].unsqueeze(0).flatten(2).permute(0, 2, 1).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYLN4RJRXXuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q['ids'].unsqueeze(0).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiLAyykeXx_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}