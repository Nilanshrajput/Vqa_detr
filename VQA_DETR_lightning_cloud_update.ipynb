{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Nilanshrajput/Vqa_detr/blob/master/DETR_Vqa_pytlightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqe_0nc5dyAq"
   },
   "source": [
    "# Object Detection with DETR - a minimal implementation\n",
    "\n",
    "In this notebook we show a demo of DETR (Detection Transformer), with slight differences with the baseline model in the paper.\n",
    "\n",
    "We show how to define the model, load pretrained weights and visualize bounding box and class predictions.\n",
    "\n",
    "Let's start with some common imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "saZ2BV_Ag0uc",
    "outputId": "69f145ad-b922-4da4-83e2-062ba90c5fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.7/site-packages (2.11.0)\n",
      "Requirement already satisfied: requests in /usr/local/share/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: filelock in /usr/local/share/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/.local/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy in /usr/local/share/anaconda3/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: packaging in /usr/local/share/anaconda3/lib/python3.7/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/.local/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.7/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/share/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /usr/local/share/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: joblib in /usr/local/share/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from packaging->transformers) (2.4.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch-lightning in /home/ubuntu/.local/lib/python3.7/site-packages (0.7.6)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from pytorch-lightning) (4.42.1)\n",
      "Requirement already satisfied: tensorboard>=1.14 in /home/ubuntu/.local/lib/python3.7/site-packages (from pytorch-lightning) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from pytorch-lightning) (1.18.1)\n",
      "Requirement already satisfied: pyyaml>=3.13 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from pytorch-lightning) (5.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: torch>=1.1 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from pytorch-lightning) (1.5.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (45.2.0.post20200210)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (2.22.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/share/anaconda3/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (0.34.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.29.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.17.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (3.12.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.6.0.post3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.14.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/share/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning) (1.5.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.4.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning) (2.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23f1c1578e9420dafcc5cf6a844c5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "example_iter = [1,2,3,4,5]\n",
    "for rec in tqdm_notebook(example_iter):\n",
    "    time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Jf59UNQ37QhJ"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel, BertModel\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import List, Dict\n",
    "import pdb\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSnU5JFxGeDe"
   },
   "source": [
    "## DETR\n",
    "Here is a minimal implementation of DETR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h91rsIPl7tVl"
   },
   "outputs": [],
   "source": [
    "class DETRdemo(nn.Module):\n",
    "    \"\"\"\n",
    "    Demo DETR implementation.\n",
    "\n",
    "    Demo implementation of DETR in minimal number of lines, with the\n",
    "    following differences wrt DETR in the paper:\n",
    "    * learned positional encoding (instead of sine)\n",
    "    * positional encoding is passed at input (instead of attention)\n",
    "    * fc bbox predictor (instead of MLP) nj\n",
    "    The model achieves ~40 AP on COCO val5k and runs at ~28 FPS on Tesla V100.\n",
    "    Only batch size 1 supported.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, hidden_dim=256, nheads=8,\n",
    "                 num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # create ResNet-50 backbone\n",
    "        self.backbone = resnet50()\n",
    "        del self.backbone.fc\n",
    "\n",
    "        # create conversion layer\n",
    "        self.conv = nn.Conv2d(2048, hidden_dim, 1)\n",
    "\n",
    "        # create a default PyTorch transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "        # prediction heads, one extra class for predicting non-empty slots\n",
    "        # note that in baseline DETR linear_bbox layer is 3-layer MLP\n",
    "        self.linear_class = nn.Linear(hidden_dim, num_classes + 1)\n",
    "        self.linear_bbox = nn.Linear(hidden_dim, 4)\n",
    "\n",
    "        # output positional encodings (object queries)\n",
    "        self.query_pos = nn.Parameter(torch.rand(100, hidden_dim))\n",
    "\n",
    "        # spatial positional encodings\n",
    "        # note that in baseline DETR we use sine positional encodings\n",
    "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "        self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # propagate inputs through ResNet-50 up to avg-pool layer\n",
    "        x = self.backbone.conv1(inputs)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        # convert from 2048 to 256 feature planes for the transformer\n",
    "        h = self.conv(x)\n",
    "        bb_ot = h\n",
    "        \n",
    "        # construct positional encodings\n",
    "        \"\"\"        H, W = h.shape[-2:]\n",
    "        pos = torch.cat([\n",
    "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1)\"\"\"\n",
    "\n",
    "        bs,_,H, W = h.shape\n",
    "        pos = torch.cat([\n",
    "        self.col_embed[:W].unsqueeze(0).unsqueeze(1).repeat(bs,H, 1, 1),\n",
    "        self.row_embed[:H].unsqueeze(0).unsqueeze(2).repeat(bs,1, W, 1),\n",
    "        ], dim=-1).flatten(1, 2)\n",
    "\n",
    "\n",
    "        #print(self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1))\n",
    "        # propagate through the transformer\n",
    "        #shape changed to (W*H,bs,hidden_dim) for both pos and h\n",
    "        h = self.transformer(pos.permute(1, 0, 2) + 0.1 * h.flatten(2).permute(2, 0, 1),\n",
    "                             self.query_pos.unsqueeze(1).repeat(1,bs,1)).transpose(0, 1)\n",
    "        \n",
    "        # finally project transformer outputs to class labels and bounding boxes\n",
    "        return {'pred_logits': self.linear_class(h), \n",
    "                'pred_boxes': self.linear_bbox(h).sigmoid(),\n",
    "                'decoder_out':h,\n",
    "                'res_out':bb_ot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dComoNKgtMEN"
   },
   "outputs": [],
   "source": [
    "class VQA_DETR(LightningModule):\n",
    "    def __init__(self,hparams,num_ans,ans_to_index,hidden_size=256, num_attention_heads = 8, num_hidden_layers = 6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hparams = hparams\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "        self.ans_to_index = ans_to_index\n",
    "        self.bert_decoder_config = BertConfig(is_decoder = True,hidden_size=hidden_size, num_attention_heads=num_attention_heads, num_hidden_layers=num_hidden_layers)\n",
    "        #self.enc_dec_config = EncoderDecoderConfig.from_encoder_decoder_configs(encoder_config= self.bert_config, decoder_config= self.bert_config)\n",
    "        #self.model = EncoderDecoderModel(config= self.enc_dec_config)\n",
    "        self.bert_decoder = BertModel(config=self.bert_decoder_config)\n",
    "\n",
    "        self.detr = DETRdemo(num_classes=91)\n",
    "        state_dict = torch.hub.load_state_dict_from_url(\n",
    "            url='https://dl.fbaipublicfiles.com/detr/detr_demo-da2a99e9.pth',\n",
    "            map_location='cpu', check_hash=True)\n",
    "        self.detr.load_state_dict(state_dict)\n",
    "        del state_dict\n",
    "        #self.detr  = self.detr.cuda()\n",
    "\n",
    "        self.classifier  = nn.Linear(hidden_size*2,num_ans)\n",
    "\n",
    "        self.drop_out = nn.Dropout(p=0.2)\n",
    "        self.log_softmax = nn.LogSoftmax().cuda()\n",
    "        \n",
    "\n",
    "    def forward(self,img, q_ids):\n",
    "        \n",
    "        img_ecs = self.detr(img)['decoder_out'].flatten(2)\n",
    "        o1,_ = self.bert_decoder(input_ids = q_ids, encoder_hidden_states = img_ecs)\n",
    "\n",
    "        mean_pool = torch.mean(o1,1)\n",
    "        max_pool,_ = torch.max(o1,1)\n",
    "        cat = torch.cat((mean_pool, max_pool),1)\n",
    "\n",
    "        bo = self.drop_out(cat)\n",
    "        output = self.classifier(bo)\n",
    "        \n",
    "        nll = -self.log_softmax(output)\n",
    "\n",
    "        return {'logits':output,'nll':nll}\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        im,q,a  = batch\n",
    "        ids = q[\"ids\"]\n",
    "\n",
    "        outputs = self(im,ids)\n",
    "        output_nll =outputs['nll']\n",
    "        logits =  outputs['logits']\n",
    "\n",
    "        loss = self.loss_fn(output_nll, a)\n",
    "        f1 = self.metric_f1(logits, a)\n",
    "        tensorboard_logs = {'train_loss': loss,'train_f1_score': f1}\n",
    "\n",
    "        return {'loss': loss, 'log': tensorboard_logs,\"progress_bar\": {'train_loss': loss,'train_f1':f1}}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        im,q,a  = batch\n",
    "        ids = q[\"ids\"]\n",
    "\n",
    "        outputs = self(im,ids)\n",
    "        output_nll =outputs['nll']\n",
    "        logits =  outputs['logits']\n",
    "\n",
    "        loss = self.loss_fn(output_nll, a)\n",
    "        f1 = self.metric_f1(logits, a)\n",
    "        tensorboard_logs = {'val_loss': loss,'val_f1_score': f1}\n",
    "\n",
    "        return {'val_loss': loss, 'log': tensorboard_logs,\"progress_bar\": {'val_loss': loss,'val_f1':f1}}\n",
    "\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        f1 = torch.stack([x['progress_bar']['val_f1'] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss,\"val_f1\":f1}\n",
    "\n",
    "    def loss_fn(self, nll, targets):\n",
    "\n",
    "        return (nll * targets / 10).sum(dim=1).mean()#nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "    \n",
    "    \n",
    "    def metric_f1(self, preds, y):\n",
    "\n",
    "        _, max_preds = preds.max(dim = -1) # get the index of the max \n",
    "        _, y = y.max(dim= -1)\n",
    "        shape = max_preds.shape[0]\n",
    "        f1=f1_score(y.detach().view(shape).numpy(),max_preds.detach().view(shape).numpy(),average='macro')\n",
    "        f1  = torch.tensor(f1, dtype  = torch.float32)\n",
    "        return f1\n",
    "\n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        param_optimizer = list(self.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "        ]\n",
    "\n",
    "        optimizer = AdamW(optimizer_parameters, lr=self.hparams.lr)\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.num_warmup_steps,\n",
    "            num_training_steps=self.total_steps(),\n",
    "        )\n",
    "\n",
    "        return [optimizer],  [{\"scheduler\": scheduler, \"interval\": \"step\"}]\n",
    "\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.val_dataset  = VQA(root='/home/ubuntu/vqa/vqa_data', answer_to_index=self.ans_to_index,split= 'val', tokenizer=self.tokenizer, max_len=15 )\n",
    "        self.train_dataset  = VQA(root='/home/ubuntu/vqa/vqa_data', answer_to_index=self.ans_to_index,split= 'train', tokenizer=self.tokenizer, max_len=15 )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        loader = DataLoader(self.train_dataset, batch_size = self.hparams.batch_size,num_workers=self.hparams.num_workers, shuffle= True)\n",
    "        return loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        loader = DataLoader(self.val_dataset, batch_size = self.hparams.val_batch_size,num_workers=self.hparams.num_workers, shuffle= False)\n",
    "        return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "7SoSX5_T7AQ1",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "97ee6c59-238e-4f22-b95d-c1aa63619384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-12 20:56:28--  https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.104.125\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.104.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "--2020-06-12 20:56:29--  http://images.cocodataset.org/zips/train2014.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.238.219\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.238.219|:80... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip\" -c -O 'v2_Annotations_Train_mscoco.zip'\n",
    "#!unzip -q v2_Annotations_Train_mscoco.zip -d /home/ubuntu/vqa/vqa_data \n",
    "!wget --header=\"Host: images.cocodataset.org\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"http://images.cocodataset.org/zips/train2014.zip\" -c -O 'train2014.zip'\n",
    "!unzip -q train2014.zip -d /home/ubuntu/vqa/vqa_data \n",
    "!rm -r train2014.zip\n",
    "!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip\" -c -O 'v2_Questions_Train_mscoco.zip'\n",
    "!unzip q v2_Questions_Train_mscoco.zip -d /home/ubuntu/vqa/vqa_data \n",
    "!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Val_mscoco.zip\" -c -O 'v2_Annotations_Val_mscoco.zip'\n",
    "!unzip -q v2_Annotations_Val_mscoco.zip -d /home/ubuntu/vqa/vqa_data \n",
    "!wget --header=\"Host: images.cocodataset.org\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"http://images.cocodataset.org/zips/val2014.zip\" -c -O 'val2014.zip'\n",
    "!unzip -q val2014.zip -d /home/ubuntu/vqa/vqa_data \n",
    "!rm -r val2014.zip\n",
    "!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip\" -c -O 'v2_Questions_Val_mscoco.zip'\n",
    "!unzip -q v2_Questions_Val_mscoco.zip -d /home/ubuntu/vqa/vqa_data \n",
    "!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Test_mscoco.zip\" -c -O 'v2_Questions_Test_mscoco.zip'\n",
    "!unzip -q v2_Questions_Test_mscoco.zip -d /home/ubuntu/vqa/vqa_data \n",
    "#!wget --header=\"Host: images.cocodataset.org\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"http://images.cocodataset.org/zips/test2015.zip\" -c -O 'test2015.zip'\n",
    "#!unzip -q test2015.zip\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-12 21:07:43--  https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.134.221\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.134.221|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "Archive:  v2_Questions_Train_mscoco.zip\n",
      "  inflating: /home/ubuntu/vqa/vqa_data/v2_OpenEnded_mscoco_train2014_questions.json  \n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: s3.amazonaws.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip\" -c -O 'v2_Questions_Train_mscoco.zip'\n",
    "!unzip v2_Questions_Train_mscoco.zip -d /home/ubuntu/vqa/vqa_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NiPadTPQbG0u"
   },
   "outputs": [],
   "source": [
    "\n",
    "def assert_eq(real, expected):\n",
    "    assert real == expected, \"%s (true) vs %s (expected)\" % (real, expected)\n",
    "\n",
    "def _create_entry(question, answer):\n",
    "    answer.pop(\"image_id\")\n",
    "    answer.pop(\"question_id\")\n",
    "    entry = {\n",
    "        \"question_id\": question[\"question_id\"],\n",
    "        \"image_id\": question[\"image_id\"],\n",
    "        \"question\": question[\"question\"],\n",
    "        \"answer\": [a['answer'] for a in answer['answers']],\n",
    "    }\n",
    "    return entry\n",
    "\n",
    "def _load_dataset(dataroot, name):\n",
    "    \"\"\"Load entries\n",
    "    dataroot: root path of dataset\n",
    "    name: 'train', 'val', 'trainval', 'minsval'\n",
    "    \"\"\"\n",
    "    if name == 'train' or name == 'val':\n",
    "        question_path = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % name)\n",
    "        questions = sorted(json.load(open(question_path))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "        answer_path = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % name)\n",
    "        answers = json.load(open(answer_path, \"rb\"))[\"annotations\"]\n",
    "        answers = sorted(answers, key=lambda x: x[\"question_id\"])\n",
    "\n",
    "    elif name  == 'trainval':\n",
    "        question_path_train = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'train')\n",
    "        questions_train = sorted(json.load(open(question_path_train))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "        answer_path_train = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'train')\n",
    "        answers_train = json.load(open(answer_path_train, \"rb\"))[\"annotations\"]\n",
    "        answers_train = sorted(answers_train, key=lambda x: x[\"question_id\"])\n",
    "\n",
    "        question_path_val = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'val')\n",
    "        questions_val = sorted(json.load(open(question_path_val))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "        answer_path_val = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'val')\n",
    "        answers_val = json.load(open(answer_path_val, \"rb\"))[\"annotations\"]\n",
    "        answers_val = sorted(answers_val, key=lambda x: x[\"question_id\"])\n",
    "        questions = questions_train + questions_val[:-3000]\n",
    "        answers = answers_train + answers_val[:-3000]\n",
    "\n",
    "    elif name == 'minval':\n",
    "        question_path_val = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'val')\n",
    "        questions_val = sorted(json.load(open(question_path_val))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "        answer_path_val = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'val')\n",
    "        answers_val = json.load(open(answer_path_val, \"rb\"))[\"annotations\"]\n",
    "        answers_val = sorted(answers_val, key=lambda x: x[\"question_id\"])        \n",
    "        questions = questions_val[-3000:]\n",
    "        answers = answers_val[-3000:]\n",
    "\n",
    "    elif name == 'test':\n",
    "        question_path_test = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2015_questions.json\" % 'test')\n",
    "        questions_test = sorted(json.load(open(question_path_test))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "        questions = questions_test\n",
    "    else:\n",
    "        assert False, \"data split is not recognized.\"\n",
    "\n",
    "    if 'test' in name:\n",
    "        entries = []\n",
    "        for question in questions:\n",
    "            entries.append(question)\n",
    "    else:\n",
    "        assert_eq(len(questions), len(answers))\n",
    "        entries = []\n",
    "        for question, answer in zip(questions, answers):\n",
    "            assert_eq(question[\"question_id\"], answer[\"question_id\"])\n",
    "            assert_eq(question[\"image_id\"], answer[\"image_id\"])\n",
    "            entries.append(_create_entry(question, answer))\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "c_KSLg6prP4J"
   },
   "outputs": [],
   "source": [
    "entries = _load_dataset(dataroot='/home/ubuntu/vqa/vqa_data',name='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tdewFhEzUU1d"
   },
   "outputs": [],
   "source": [
    "# compile a list of all the answers\n",
    "all_answers  = set()\n",
    "for a in entries:\n",
    "    all_answers.update(a['answer'])\n",
    "all_answers=list(all_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "d-Q_quxQmxOv"
   },
   "outputs": [],
   "source": [
    "answer_to_index = dict()\n",
    "for i,answer in enumerate(all_answers):\n",
    "    answer_to_index[answer]=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BBlfQ2YngeTd"
   },
   "outputs": [],
   "source": [
    "class VQA(data.Dataset):\n",
    "    \"\"\" VQA dataset, open-ended \"\"\"\n",
    "    def __init__(self, root, answer_to_index, tokenizer ,split = 'train', max_len = 20):\n",
    "        super(VQA, self).__init__()\n",
    "\n",
    "\n",
    "        self.root = root\n",
    "        self.answer_to_index = answer_to_index\n",
    "        self.split = split\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.entries = self._load_dataset( self.root, self.split)\n",
    "\n",
    "         # standard PyTorch mean-std input image normalization\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize(size=(800,800)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.id_to_image_fname = self._find_iamges()\n",
    "\n",
    "\n",
    "    def assert_eq(self,real, expected):\n",
    "        assert real == expected, \"%s (true) vs %s (expected)\" % (real, expected)\n",
    "\n",
    "    def _create_entry(self,question, answer):\n",
    "        answer.pop(\"image_id\")\n",
    "        answer.pop(\"question_id\")\n",
    "        entry = {\n",
    "            \"question_id\": question[\"question_id\"],\n",
    "            \"image_id\": question[\"image_id\"],\n",
    "            \"question\": question[\"question\"],\n",
    "            \"answer\": [a['answer'] for a in answer['answers']],\n",
    "        }\n",
    "        return entry\n",
    "\n",
    "    def _load_dataset(self,dataroot, name):\n",
    "        \"\"\"Load entries\n",
    "        dataroot: root path of dataset\n",
    "        name: 'train', 'val', 'trainval', 'minsval'\n",
    "        \"\"\"\n",
    "        if name == 'train' or name == 'val':\n",
    "            question_path = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % name)\n",
    "            questions = sorted(json.load(open(question_path))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "            answer_path = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % name)\n",
    "            answers = json.load(open(answer_path, \"rb\"))[\"annotations\"]\n",
    "            answers = sorted(answers, key=lambda x: x[\"question_id\"])\n",
    "\n",
    "        elif name  == 'trainval':\n",
    "            question_path_train = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'train')\n",
    "            questions_train = sorted(json.load(open(question_path_train))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "            answer_path_train = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'train')\n",
    "            answers_train = json.load(open(answer_path_train, \"rb\"))[\"annotations\"]\n",
    "            answers_train = sorted(answers_train, key=lambda x: x[\"question_id\"])\n",
    "\n",
    "            question_path_val = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'val')\n",
    "            questions_val = sorted(json.load(open(question_path_val))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "            answer_path_val = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'val')\n",
    "            answers_val = json.load(open(answer_path_val, \"rb\"))[\"annotations\"]\n",
    "            answers_val = sorted(answers_val, key=lambda x: x[\"question_id\"])\n",
    "            questions = questions_train + questions_val[:-3000]\n",
    "            answers = answers_train + answers_val[:-3000]\n",
    "\n",
    "        elif name == 'minval':\n",
    "            question_path_val = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2014_questions.json\" % 'val')\n",
    "            questions_val = sorted(json.load(open(question_path_val))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "            answer_path_val = os.path.join(dataroot, \"v2_mscoco_%s2014_annotations.json\" % 'val')\n",
    "            answers_val = json.load(open(answer_path_val, \"rb\"))[\"annotations\"]\n",
    "            answers_val = sorted(answers_val, key=lambda x: x[\"question_id\"])        \n",
    "            questions = questions_val[-3000:]\n",
    "            answers = answers_val[-3000:]\n",
    "\n",
    "        elif name == 'test':\n",
    "            question_path_test = os.path.join(dataroot, \"v2_OpenEnded_mscoco_%s2015_questions.json\" % 'test')\n",
    "            questions_test = sorted(json.load(open(question_path_test))[\"questions\"], key=lambda x: x[\"question_id\"])\n",
    "            questions = questions_test\n",
    "        else:\n",
    "            assert False, \"data split is not recognized.\"\n",
    "\n",
    "        if 'test' in name:\n",
    "            entries = []\n",
    "            for question in questions:\n",
    "                entries.append(question)\n",
    "        else:\n",
    "            assert_eq(len(questions), len(answers))\n",
    "            entries = []\n",
    "            for question, answer in zip(questions, answers):\n",
    "                assert_eq(question[\"question_id\"], answer[\"question_id\"])\n",
    "                assert_eq(question[\"image_id\"], answer[\"image_id\"])\n",
    "                entries.append(_create_entry(question, answer))\n",
    "        return entries\n",
    "\n",
    "\n",
    "\n",
    "    def _encode_question(self, question):\n",
    "        \"\"\" Turn a question into a vector of indices and a question length \"\"\"\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        padding_length = self.max_len - len(ids)\n",
    "        ids += ([0]*padding_length)\n",
    "        mask += ([0]*padding_length)\n",
    "        token_type_ids += ([0]*padding_length)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \n",
    "        }\n",
    "\n",
    "    def _encode_ansfor_bert(self, answers):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def _encode_answers(self, answers):\n",
    "        \"\"\" Turn an answer into a vector \"\"\"\n",
    "        # answer vec will be a vector of answer counts to determine which answers will contribute to the loss.\n",
    "        # this should be multiplied with 0.1 * negative log-likelihoods that a model produces and then summed up\n",
    "        # to get the loss that is weighted by how many humans gave that answer\n",
    "        answer_vec = torch.zeros(len(self.answer_to_index),dtype=torch.long)\n",
    "        for answer in answers:\n",
    "            index = self.answer_to_index.get(answer)\n",
    "            if index is not None:\n",
    "                answer_vec[index] += 1\n",
    "        return answer_vec\n",
    "\n",
    "   \n",
    "    def _find_iamges(self):\n",
    "        id_to_filename = {}\n",
    "        imgs_folder = os.path.join(self.root,'%s2014'%self.split)\n",
    "        for filename in os.listdir(imgs_folder):\n",
    "            if not filename.endswith('.jpg'):\n",
    "                continue\n",
    "            id_and_extension = filename.split('_')[-1]\n",
    "            id = int(id_and_extension.split('.')[0])\n",
    "            id_to_filename[id] = os.path.join(imgs_folder,filename)\n",
    "        return id_to_filename\n",
    "\n",
    "\n",
    "    def _load_image(self, image_id):\n",
    "        \"\"\" Load an image \"\"\"\n",
    "\n",
    "        img_path = self.id_to_image_fname[image_id]\n",
    "        img  = Image.open(img_path)\n",
    "        img = np.asarray(img)\n",
    "        \n",
    "        if len(img.shape)==2:\n",
    "            print(img.shape)\n",
    "            img=np.expand_dims(img, axis=-1)\n",
    "            \n",
    "            img = np.repeat(img,3, axis = -1)\n",
    "            print(img.shape)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "       \n",
    "        entry  = self.entries[item]\n",
    "        image_id = entry['image_id']\n",
    "\n",
    "        img = self._load_image(image_id)\n",
    "        q = entry['question']\n",
    "        a = self._encode_answers(entry['answer'])\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        #question_id = entry['question_id']\n",
    "        q= self._encode_question(q)\n",
    "\n",
    "        return img, q, a\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"The collat_fn method to be used by the\n",
    "        PyTorch data loader.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Unzip the batch\n",
    "\n",
    "        imgs,qs, answers = list(zip(*batch))\n",
    "\n",
    "        # concatenate the vectors\n",
    "        imgs = torch.stack(imgs)\n",
    "        \n",
    "        #concatenate the labels\n",
    "        q = torch.stack(qs)\n",
    "\n",
    "        a = torch.stack(answers)\n",
    "        \n",
    "        return imgs, q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "UKR94pUILXJm"
   },
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    batch_size=1,\n",
    "    val_batch_size=1,\n",
    "    num_warmup_steps=100,\n",
    "    epochs=20,\n",
    "    lr=3e-5,\n",
    "    accumulate_grad_batches=1,\n",
    "    num_workers = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ans = len(answer_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "uhbtt7a2OfCk",
    "outputId": "0dbea896-b353-4924-94f8-b4819cd44fb0"
   },
   "outputs": [],
   "source": [
    "vqa_detr = VQA_DETR(num_ans=len_ans,ans_to_index=answer_to_index,hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "YGZ-OqgvOe-u",
    "outputId": "a87f41f7-904f-476e-9d5b-bafee564ccdb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "GPU available: True, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "\n",
      "    | Name                                                         | Type                    | Params\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "0   | bert_decoder                                                 | BertModel               | 20 M  \n",
      "1   | bert_decoder.embeddings                                      | BertEmbeddings          | 7 M   \n",
      "2   | bert_decoder.embeddings.word_embeddings                      | Embedding               | 7 M   \n",
      "3   | bert_decoder.embeddings.position_embeddings                  | Embedding               | 131 K \n",
      "4   | bert_decoder.embeddings.token_type_embeddings                | Embedding               | 512   \n",
      "5   | bert_decoder.embeddings.LayerNorm                            | LayerNorm               | 512   \n",
      "6   | bert_decoder.embeddings.dropout                              | Dropout                 | 0     \n",
      "7   | bert_decoder.encoder                                         | BertEncoder             | 12 M  \n",
      "8   | bert_decoder.encoder.layer                                   | ModuleList              | 12 M  \n",
      "9   | bert_decoder.encoder.layer.0                                 | BertLayer               | 2 M   \n",
      "10  | bert_decoder.encoder.layer.0.attention                       | BertAttention           | 263 K \n",
      "11  | bert_decoder.encoder.layer.0.attention.self                  | BertSelfAttention       | 197 K \n",
      "12  | bert_decoder.encoder.layer.0.attention.self.query            | Linear                  | 65 K  \n",
      "13  | bert_decoder.encoder.layer.0.attention.self.key              | Linear                  | 65 K  \n",
      "14  | bert_decoder.encoder.layer.0.attention.self.value            | Linear                  | 65 K  \n",
      "15  | bert_decoder.encoder.layer.0.attention.self.dropout          | Dropout                 | 0     \n",
      "16  | bert_decoder.encoder.layer.0.attention.output                | BertSelfOutput          | 66 K  \n",
      "17  | bert_decoder.encoder.layer.0.attention.output.dense          | Linear                  | 65 K  \n",
      "18  | bert_decoder.encoder.layer.0.attention.output.LayerNorm      | LayerNorm               | 512   \n",
      "19  | bert_decoder.encoder.layer.0.attention.output.dropout        | Dropout                 | 0     \n",
      "20  | bert_decoder.encoder.layer.0.crossattention                  | BertAttention           | 263 K \n",
      "21  | bert_decoder.encoder.layer.0.crossattention.self             | BertSelfAttention       | 197 K \n",
      "22  | bert_decoder.encoder.layer.0.crossattention.self.query       | Linear                  | 65 K  \n",
      "23  | bert_decoder.encoder.layer.0.crossattention.self.key         | Linear                  | 65 K  \n",
      "24  | bert_decoder.encoder.layer.0.crossattention.self.value       | Linear                  | 65 K  \n",
      "25  | bert_decoder.encoder.layer.0.crossattention.self.dropout     | Dropout                 | 0     \n",
      "26  | bert_decoder.encoder.layer.0.crossattention.output           | BertSelfOutput          | 66 K  \n",
      "27  | bert_decoder.encoder.layer.0.crossattention.output.dense     | Linear                  | 65 K  \n",
      "28  | bert_decoder.encoder.layer.0.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
      "29  | bert_decoder.encoder.layer.0.crossattention.output.dropout   | Dropout                 | 0     \n",
      "30  | bert_decoder.encoder.layer.0.intermediate                    | BertIntermediate        | 789 K \n",
      "31  | bert_decoder.encoder.layer.0.intermediate.dense              | Linear                  | 789 K \n",
      "32  | bert_decoder.encoder.layer.0.output                          | BertOutput              | 787 K \n",
      "33  | bert_decoder.encoder.layer.0.output.dense                    | Linear                  | 786 K \n",
      "34  | bert_decoder.encoder.layer.0.output.LayerNorm                | LayerNorm               | 512   \n",
      "35  | bert_decoder.encoder.layer.0.output.dropout                  | Dropout                 | 0     \n",
      "36  | bert_decoder.encoder.layer.1                                 | BertLayer               | 2 M   \n",
      "37  | bert_decoder.encoder.layer.1.attention                       | BertAttention           | 263 K \n",
      "38  | bert_decoder.encoder.layer.1.attention.self                  | BertSelfAttention       | 197 K \n",
      "39  | bert_decoder.encoder.layer.1.attention.self.query            | Linear                  | 65 K  \n",
      "40  | bert_decoder.encoder.layer.1.attention.self.key              | Linear                  | 65 K  \n",
      "41  | bert_decoder.encoder.layer.1.attention.self.value            | Linear                  | 65 K  \n",
      "42  | bert_decoder.encoder.layer.1.attention.self.dropout          | Dropout                 | 0     \n",
      "43  | bert_decoder.encoder.layer.1.attention.output                | BertSelfOutput          | 66 K  \n",
      "44  | bert_decoder.encoder.layer.1.attention.output.dense          | Linear                  | 65 K  \n",
      "45  | bert_decoder.encoder.layer.1.attention.output.LayerNorm      | LayerNorm               | 512   \n",
      "46  | bert_decoder.encoder.layer.1.attention.output.dropout        | Dropout                 | 0     \n",
      "47  | bert_decoder.encoder.layer.1.crossattention                  | BertAttention           | 263 K \n",
      "48  | bert_decoder.encoder.layer.1.crossattention.self             | BertSelfAttention       | 197 K \n",
      "49  | bert_decoder.encoder.layer.1.crossattention.self.query       | Linear                  | 65 K  \n",
      "50  | bert_decoder.encoder.layer.1.crossattention.self.key         | Linear                  | 65 K  \n",
      "51  | bert_decoder.encoder.layer.1.crossattention.self.value       | Linear                  | 65 K  \n",
      "52  | bert_decoder.encoder.layer.1.crossattention.self.dropout     | Dropout                 | 0     \n",
      "53  | bert_decoder.encoder.layer.1.crossattention.output           | BertSelfOutput          | 66 K  \n",
      "54  | bert_decoder.encoder.layer.1.crossattention.output.dense     | Linear                  | 65 K  \n",
      "55  | bert_decoder.encoder.layer.1.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
      "56  | bert_decoder.encoder.layer.1.crossattention.output.dropout   | Dropout                 | 0     \n",
      "57  | bert_decoder.encoder.layer.1.intermediate                    | BertIntermediate        | 789 K \n",
      "58  | bert_decoder.encoder.layer.1.intermediate.dense              | Linear                  | 789 K \n",
      "59  | bert_decoder.encoder.layer.1.output                          | BertOutput              | 787 K \n",
      "60  | bert_decoder.encoder.layer.1.output.dense                    | Linear                  | 786 K \n",
      "61  | bert_decoder.encoder.layer.1.output.LayerNorm                | LayerNorm               | 512   \n",
      "62  | bert_decoder.encoder.layer.1.output.dropout                  | Dropout                 | 0     \n",
      "63  | bert_decoder.encoder.layer.2                                 | BertLayer               | 2 M   \n",
      "64  | bert_decoder.encoder.layer.2.attention                       | BertAttention           | 263 K \n",
      "65  | bert_decoder.encoder.layer.2.attention.self                  | BertSelfAttention       | 197 K \n",
      "66  | bert_decoder.encoder.layer.2.attention.self.query            | Linear                  | 65 K  \n",
      "67  | bert_decoder.encoder.layer.2.attention.self.key              | Linear                  | 65 K  \n",
      "68  | bert_decoder.encoder.layer.2.attention.self.value            | Linear                  | 65 K  \n",
      "69  | bert_decoder.encoder.layer.2.attention.self.dropout          | Dropout                 | 0     \n",
      "70  | bert_decoder.encoder.layer.2.attention.output                | BertSelfOutput          | 66 K  \n",
      "71  | bert_decoder.encoder.layer.2.attention.output.dense          | Linear                  | 65 K  \n",
      "72  | bert_decoder.encoder.layer.2.attention.output.LayerNorm      | LayerNorm               | 512   \n",
      "73  | bert_decoder.encoder.layer.2.attention.output.dropout        | Dropout                 | 0     \n",
      "74  | bert_decoder.encoder.layer.2.crossattention                  | BertAttention           | 263 K \n",
      "75  | bert_decoder.encoder.layer.2.crossattention.self             | BertSelfAttention       | 197 K \n",
      "76  | bert_decoder.encoder.layer.2.crossattention.self.query       | Linear                  | 65 K  \n",
      "77  | bert_decoder.encoder.layer.2.crossattention.self.key         | Linear                  | 65 K  \n",
      "78  | bert_decoder.encoder.layer.2.crossattention.self.value       | Linear                  | 65 K  \n",
      "79  | bert_decoder.encoder.layer.2.crossattention.self.dropout     | Dropout                 | 0     \n",
      "80  | bert_decoder.encoder.layer.2.crossattention.output           | BertSelfOutput          | 66 K  \n",
      "81  | bert_decoder.encoder.layer.2.crossattention.output.dense     | Linear                  | 65 K  \n",
      "82  | bert_decoder.encoder.layer.2.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
      "83  | bert_decoder.encoder.layer.2.crossattention.output.dropout   | Dropout                 | 0     \n",
      "84  | bert_decoder.encoder.layer.2.intermediate                    | BertIntermediate        | 789 K \n",
      "85  | bert_decoder.encoder.layer.2.intermediate.dense              | Linear                  | 789 K \n",
      "86  | bert_decoder.encoder.layer.2.output                          | BertOutput              | 787 K \n",
      "87  | bert_decoder.encoder.layer.2.output.dense                    | Linear                  | 786 K \n",
      "88  | bert_decoder.encoder.layer.2.output.LayerNorm                | LayerNorm               | 512   \n",
      "89  | bert_decoder.encoder.layer.2.output.dropout                  | Dropout                 | 0     \n",
      "90  | bert_decoder.encoder.layer.3                                 | BertLayer               | 2 M   \n",
      "91  | bert_decoder.encoder.layer.3.attention                       | BertAttention           | 263 K \n",
      "92  | bert_decoder.encoder.layer.3.attention.self                  | BertSelfAttention       | 197 K \n",
      "93  | bert_decoder.encoder.layer.3.attention.self.query            | Linear                  | 65 K  \n",
      "94  | bert_decoder.encoder.layer.3.attention.self.key              | Linear                  | 65 K  \n",
      "95  | bert_decoder.encoder.layer.3.attention.self.value            | Linear                  | 65 K  \n",
      "96  | bert_decoder.encoder.layer.3.attention.self.dropout          | Dropout                 | 0     \n",
      "97  | bert_decoder.encoder.layer.3.attention.output                | BertSelfOutput          | 66 K  \n",
      "98  | bert_decoder.encoder.layer.3.attention.output.dense          | Linear                  | 65 K  \n",
      "99  | bert_decoder.encoder.layer.3.attention.output.LayerNorm      | LayerNorm               | 512   \n",
      "100 | bert_decoder.encoder.layer.3.attention.output.dropout        | Dropout                 | 0     \n",
      "101 | bert_decoder.encoder.layer.3.crossattention                  | BertAttention           | 263 K \n",
      "102 | bert_decoder.encoder.layer.3.crossattention.self             | BertSelfAttention       | 197 K \n",
      "103 | bert_decoder.encoder.layer.3.crossattention.self.query       | Linear                  | 65 K  \n",
      "104 | bert_decoder.encoder.layer.3.crossattention.self.key         | Linear                  | 65 K  \n",
      "105 | bert_decoder.encoder.layer.3.crossattention.self.value       | Linear                  | 65 K  \n",
      "106 | bert_decoder.encoder.layer.3.crossattention.self.dropout     | Dropout                 | 0     \n",
      "107 | bert_decoder.encoder.layer.3.crossattention.output           | BertSelfOutput          | 66 K  \n",
      "108 | bert_decoder.encoder.layer.3.crossattention.output.dense     | Linear                  | 65 K  \n",
      "109 | bert_decoder.encoder.layer.3.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
      "110 | bert_decoder.encoder.layer.3.crossattention.output.dropout   | Dropout                 | 0     \n",
      "111 | bert_decoder.encoder.layer.3.intermediate                    | BertIntermediate        | 789 K \n",
      "112 | bert_decoder.encoder.layer.3.intermediate.dense              | Linear                  | 789 K \n",
      "113 | bert_decoder.encoder.layer.3.output                          | BertOutput              | 787 K \n",
      "114 | bert_decoder.encoder.layer.3.output.dense                    | Linear                  | 786 K \n",
      "115 | bert_decoder.encoder.layer.3.output.LayerNorm                | LayerNorm               | 512   \n",
      "116 | bert_decoder.encoder.layer.3.output.dropout                  | Dropout                 | 0     \n",
      "117 | bert_decoder.encoder.layer.4                                 | BertLayer               | 2 M   \n",
      "118 | bert_decoder.encoder.layer.4.attention                       | BertAttention           | 263 K \n",
      "119 | bert_decoder.encoder.layer.4.attention.self                  | BertSelfAttention       | 197 K \n",
      "120 | bert_decoder.encoder.layer.4.attention.self.query            | Linear                  | 65 K  \n",
      "121 | bert_decoder.encoder.layer.4.attention.self.key              | Linear                  | 65 K  \n",
      "122 | bert_decoder.encoder.layer.4.attention.self.value            | Linear                  | 65 K  \n",
      "123 | bert_decoder.encoder.layer.4.attention.self.dropout          | Dropout                 | 0     \n",
      "124 | bert_decoder.encoder.layer.4.attention.output                | BertSelfOutput          | 66 K  \n",
      "125 | bert_decoder.encoder.layer.4.attention.output.dense          | Linear                  | 65 K  \n",
      "126 | bert_decoder.encoder.layer.4.attention.output.LayerNorm      | LayerNorm               | 512   \n",
      "127 | bert_decoder.encoder.layer.4.attention.output.dropout        | Dropout                 | 0     \n",
      "128 | bert_decoder.encoder.layer.4.crossattention                  | BertAttention           | 263 K \n",
      "129 | bert_decoder.encoder.layer.4.crossattention.self             | BertSelfAttention       | 197 K \n",
      "130 | bert_decoder.encoder.layer.4.crossattention.self.query       | Linear                  | 65 K  \n",
      "131 | bert_decoder.encoder.layer.4.crossattention.self.key         | Linear                  | 65 K  \n",
      "132 | bert_decoder.encoder.layer.4.crossattention.self.value       | Linear                  | 65 K  \n",
      "133 | bert_decoder.encoder.layer.4.crossattention.self.dropout     | Dropout                 | 0     \n",
      "134 | bert_decoder.encoder.layer.4.crossattention.output           | BertSelfOutput          | 66 K  \n",
      "135 | bert_decoder.encoder.layer.4.crossattention.output.dense     | Linear                  | 65 K  \n",
      "136 | bert_decoder.encoder.layer.4.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
      "137 | bert_decoder.encoder.layer.4.crossattention.output.dropout   | Dropout                 | 0     \n",
      "138 | bert_decoder.encoder.layer.4.intermediate                    | BertIntermediate        | 789 K \n",
      "139 | bert_decoder.encoder.layer.4.intermediate.dense              | Linear                  | 789 K \n",
      "140 | bert_decoder.encoder.layer.4.output                          | BertOutput              | 787 K \n",
      "141 | bert_decoder.encoder.layer.4.output.dense                    | Linear                  | 786 K \n",
      "142 | bert_decoder.encoder.layer.4.output.LayerNorm                | LayerNorm               | 512   \n",
      "143 | bert_decoder.encoder.layer.4.output.dropout                  | Dropout                 | 0     \n",
      "144 | bert_decoder.encoder.layer.5                                 | BertLayer               | 2 M   \n",
      "145 | bert_decoder.encoder.layer.5.attention                       | BertAttention           | 263 K \n",
      "146 | bert_decoder.encoder.layer.5.attention.self                  | BertSelfAttention       | 197 K \n",
      "147 | bert_decoder.encoder.layer.5.attention.self.query            | Linear                  | 65 K  \n",
      "148 | bert_decoder.encoder.layer.5.attention.self.key              | Linear                  | 65 K  \n",
      "149 | bert_decoder.encoder.layer.5.attention.self.value            | Linear                  | 65 K  \n",
      "150 | bert_decoder.encoder.layer.5.attention.self.dropout          | Dropout                 | 0     \n",
      "151 | bert_decoder.encoder.layer.5.attention.output                | BertSelfOutput          | 66 K  \n",
      "152 | bert_decoder.encoder.layer.5.attention.output.dense          | Linear                  | 65 K  \n",
      "153 | bert_decoder.encoder.layer.5.attention.output.LayerNorm      | LayerNorm               | 512   \n",
      "154 | bert_decoder.encoder.layer.5.attention.output.dropout        | Dropout                 | 0     \n",
      "155 | bert_decoder.encoder.layer.5.crossattention                  | BertAttention           | 263 K \n",
      "156 | bert_decoder.encoder.layer.5.crossattention.self             | BertSelfAttention       | 197 K \n",
      "157 | bert_decoder.encoder.layer.5.crossattention.self.query       | Linear                  | 65 K  \n",
      "158 | bert_decoder.encoder.layer.5.crossattention.self.key         | Linear                  | 65 K  \n",
      "159 | bert_decoder.encoder.layer.5.crossattention.self.value       | Linear                  | 65 K  \n",
      "160 | bert_decoder.encoder.layer.5.crossattention.self.dropout     | Dropout                 | 0     \n",
      "161 | bert_decoder.encoder.layer.5.crossattention.output           | BertSelfOutput          | 66 K  \n",
      "162 | bert_decoder.encoder.layer.5.crossattention.output.dense     | Linear                  | 65 K  \n",
      "163 | bert_decoder.encoder.layer.5.crossattention.output.LayerNorm | LayerNorm               | 512   \n",
      "164 | bert_decoder.encoder.layer.5.crossattention.output.dropout   | Dropout                 | 0     \n",
      "165 | bert_decoder.encoder.layer.5.intermediate                    | BertIntermediate        | 789 K \n",
      "166 | bert_decoder.encoder.layer.5.intermediate.dense              | Linear                  | 789 K \n",
      "167 | bert_decoder.encoder.layer.5.output                          | BertOutput              | 787 K \n",
      "168 | bert_decoder.encoder.layer.5.output.dense                    | Linear                  | 786 K \n",
      "169 | bert_decoder.encoder.layer.5.output.LayerNorm                | LayerNorm               | 512   \n",
      "170 | bert_decoder.encoder.layer.5.output.dropout                  | Dropout                 | 0     \n",
      "171 | bert_decoder.pooler                                          | BertPooler              | 65 K  \n",
      "172 | bert_decoder.pooler.dense                                    | Linear                  | 65 K  \n",
      "173 | bert_decoder.pooler.activation                               | Tanh                    | 0     \n",
      "174 | detr                                                         | DETRdemo                | 41 M  \n",
      "175 | detr.backbone                                                | ResNet                  | 23 M  \n",
      "176 | detr.backbone.conv1                                          | Conv2d                  | 9 K   \n",
      "177 | detr.backbone.bn1                                            | BatchNorm2d             | 128   \n",
      "178 | detr.backbone.relu                                           | ReLU                    | 0     \n",
      "179 | detr.backbone.maxpool                                        | MaxPool2d               | 0     \n",
      "180 | detr.backbone.layer1                                         | Sequential              | 215 K \n",
      "181 | detr.backbone.layer1.0                                       | Bottleneck              | 75 K  \n",
      "182 | detr.backbone.layer1.0.conv1                                 | Conv2d                  | 4 K   \n",
      "183 | detr.backbone.layer1.0.bn1                                   | BatchNorm2d             | 128   \n",
      "184 | detr.backbone.layer1.0.conv2                                 | Conv2d                  | 36 K  \n",
      "185 | detr.backbone.layer1.0.bn2                                   | BatchNorm2d             | 128   \n",
      "186 | detr.backbone.layer1.0.conv3                                 | Conv2d                  | 16 K  \n",
      "187 | detr.backbone.layer1.0.bn3                                   | BatchNorm2d             | 512   \n",
      "188 | detr.backbone.layer1.0.relu                                  | ReLU                    | 0     \n",
      "189 | detr.backbone.layer1.0.downsample                            | Sequential              | 16 K  \n",
      "190 | detr.backbone.layer1.0.downsample.0                          | Conv2d                  | 16 K  \n",
      "191 | detr.backbone.layer1.0.downsample.1                          | BatchNorm2d             | 512   \n",
      "192 | detr.backbone.layer1.1                                       | Bottleneck              | 70 K  \n",
      "193 | detr.backbone.layer1.1.conv1                                 | Conv2d                  | 16 K  \n",
      "194 | detr.backbone.layer1.1.bn1                                   | BatchNorm2d             | 128   \n",
      "195 | detr.backbone.layer1.1.conv2                                 | Conv2d                  | 36 K  \n",
      "196 | detr.backbone.layer1.1.bn2                                   | BatchNorm2d             | 128   \n",
      "197 | detr.backbone.layer1.1.conv3                                 | Conv2d                  | 16 K  \n",
      "198 | detr.backbone.layer1.1.bn3                                   | BatchNorm2d             | 512   \n",
      "199 | detr.backbone.layer1.1.relu                                  | ReLU                    | 0     \n",
      "200 | detr.backbone.layer1.2                                       | Bottleneck              | 70 K  \n",
      "201 | detr.backbone.layer1.2.conv1                                 | Conv2d                  | 16 K  \n",
      "202 | detr.backbone.layer1.2.bn1                                   | BatchNorm2d             | 128   \n",
      "203 | detr.backbone.layer1.2.conv2                                 | Conv2d                  | 36 K  \n",
      "204 | detr.backbone.layer1.2.bn2                                   | BatchNorm2d             | 128   \n",
      "205 | detr.backbone.layer1.2.conv3                                 | Conv2d                  | 16 K  \n",
      "206 | detr.backbone.layer1.2.bn3                                   | BatchNorm2d             | 512   \n",
      "207 | detr.backbone.layer1.2.relu                                  | ReLU                    | 0     \n",
      "208 | detr.backbone.layer2                                         | Sequential              | 1 M   \n",
      "209 | detr.backbone.layer2.0                                       | Bottleneck              | 379 K \n",
      "210 | detr.backbone.layer2.0.conv1                                 | Conv2d                  | 32 K  \n",
      "211 | detr.backbone.layer2.0.bn1                                   | BatchNorm2d             | 256   \n",
      "212 | detr.backbone.layer2.0.conv2                                 | Conv2d                  | 147 K \n",
      "213 | detr.backbone.layer2.0.bn2                                   | BatchNorm2d             | 256   \n",
      "214 | detr.backbone.layer2.0.conv3                                 | Conv2d                  | 65 K  \n",
      "215 | detr.backbone.layer2.0.bn3                                   | BatchNorm2d             | 1 K   \n",
      "216 | detr.backbone.layer2.0.relu                                  | ReLU                    | 0     \n",
      "217 | detr.backbone.layer2.0.downsample                            | Sequential              | 132 K \n",
      "218 | detr.backbone.layer2.0.downsample.0                          | Conv2d                  | 131 K \n",
      "219 | detr.backbone.layer2.0.downsample.1                          | BatchNorm2d             | 1 K   \n",
      "220 | detr.backbone.layer2.1                                       | Bottleneck              | 280 K \n",
      "221 | detr.backbone.layer2.1.conv1                                 | Conv2d                  | 65 K  \n",
      "222 | detr.backbone.layer2.1.bn1                                   | BatchNorm2d             | 256   \n",
      "223 | detr.backbone.layer2.1.conv2                                 | Conv2d                  | 147 K \n",
      "224 | detr.backbone.layer2.1.bn2                                   | BatchNorm2d             | 256   \n",
      "225 | detr.backbone.layer2.1.conv3                                 | Conv2d                  | 65 K  \n",
      "226 | detr.backbone.layer2.1.bn3                                   | BatchNorm2d             | 1 K   \n",
      "227 | detr.backbone.layer2.1.relu                                  | ReLU                    | 0     \n",
      "228 | detr.backbone.layer2.2                                       | Bottleneck              | 280 K \n",
      "229 | detr.backbone.layer2.2.conv1                                 | Conv2d                  | 65 K  \n",
      "230 | detr.backbone.layer2.2.bn1                                   | BatchNorm2d             | 256   \n",
      "231 | detr.backbone.layer2.2.conv2                                 | Conv2d                  | 147 K \n",
      "232 | detr.backbone.layer2.2.bn2                                   | BatchNorm2d             | 256   \n",
      "233 | detr.backbone.layer2.2.conv3                                 | Conv2d                  | 65 K  \n",
      "234 | detr.backbone.layer2.2.bn3                                   | BatchNorm2d             | 1 K   \n",
      "235 | detr.backbone.layer2.2.relu                                  | ReLU                    | 0     \n",
      "236 | detr.backbone.layer2.3                                       | Bottleneck              | 280 K \n",
      "237 | detr.backbone.layer2.3.conv1                                 | Conv2d                  | 65 K  \n",
      "238 | detr.backbone.layer2.3.bn1                                   | BatchNorm2d             | 256   \n",
      "239 | detr.backbone.layer2.3.conv2                                 | Conv2d                  | 147 K \n",
      "240 | detr.backbone.layer2.3.bn2                                   | BatchNorm2d             | 256   \n",
      "241 | detr.backbone.layer2.3.conv3                                 | Conv2d                  | 65 K  \n",
      "242 | detr.backbone.layer2.3.bn3                                   | BatchNorm2d             | 1 K   \n",
      "243 | detr.backbone.layer2.3.relu                                  | ReLU                    | 0     \n",
      "244 | detr.backbone.layer3                                         | Sequential              | 7 M   \n",
      "245 | detr.backbone.layer3.0                                       | Bottleneck              | 1 M   \n",
      "246 | detr.backbone.layer3.0.conv1                                 | Conv2d                  | 131 K \n",
      "247 | detr.backbone.layer3.0.bn1                                   | BatchNorm2d             | 512   \n",
      "248 | detr.backbone.layer3.0.conv2                                 | Conv2d                  | 589 K \n",
      "249 | detr.backbone.layer3.0.bn2                                   | BatchNorm2d             | 512   \n",
      "250 | detr.backbone.layer3.0.conv3                                 | Conv2d                  | 262 K \n",
      "251 | detr.backbone.layer3.0.bn3                                   | BatchNorm2d             | 2 K   \n",
      "252 | detr.backbone.layer3.0.relu                                  | ReLU                    | 0     \n",
      "253 | detr.backbone.layer3.0.downsample                            | Sequential              | 526 K \n",
      "254 | detr.backbone.layer3.0.downsample.0                          | Conv2d                  | 524 K \n",
      "255 | detr.backbone.layer3.0.downsample.1                          | BatchNorm2d             | 2 K   \n",
      "256 | detr.backbone.layer3.1                                       | Bottleneck              | 1 M   \n",
      "257 | detr.backbone.layer3.1.conv1                                 | Conv2d                  | 262 K \n",
      "258 | detr.backbone.layer3.1.bn1                                   | BatchNorm2d             | 512   \n",
      "259 | detr.backbone.layer3.1.conv2                                 | Conv2d                  | 589 K \n",
      "260 | detr.backbone.layer3.1.bn2                                   | BatchNorm2d             | 512   \n",
      "261 | detr.backbone.layer3.1.conv3                                 | Conv2d                  | 262 K \n",
      "262 | detr.backbone.layer3.1.bn3                                   | BatchNorm2d             | 2 K   \n",
      "263 | detr.backbone.layer3.1.relu                                  | ReLU                    | 0     \n",
      "264 | detr.backbone.layer3.2                                       | Bottleneck              | 1 M   \n",
      "265 | detr.backbone.layer3.2.conv1                                 | Conv2d                  | 262 K \n",
      "266 | detr.backbone.layer3.2.bn1                                   | BatchNorm2d             | 512   \n",
      "267 | detr.backbone.layer3.2.conv2                                 | Conv2d                  | 589 K \n",
      "268 | detr.backbone.layer3.2.bn2                                   | BatchNorm2d             | 512   \n",
      "269 | detr.backbone.layer3.2.conv3                                 | Conv2d                  | 262 K \n",
      "270 | detr.backbone.layer3.2.bn3                                   | BatchNorm2d             | 2 K   \n",
      "271 | detr.backbone.layer3.2.relu                                  | ReLU                    | 0     \n",
      "272 | detr.backbone.layer3.3                                       | Bottleneck              | 1 M   \n",
      "273 | detr.backbone.layer3.3.conv1                                 | Conv2d                  | 262 K \n",
      "274 | detr.backbone.layer3.3.bn1                                   | BatchNorm2d             | 512   \n",
      "275 | detr.backbone.layer3.3.conv2                                 | Conv2d                  | 589 K \n",
      "276 | detr.backbone.layer3.3.bn2                                   | BatchNorm2d             | 512   \n",
      "277 | detr.backbone.layer3.3.conv3                                 | Conv2d                  | 262 K \n",
      "278 | detr.backbone.layer3.3.bn3                                   | BatchNorm2d             | 2 K   \n",
      "279 | detr.backbone.layer3.3.relu                                  | ReLU                    | 0     \n",
      "280 | detr.backbone.layer3.4                                       | Bottleneck              | 1 M   \n",
      "281 | detr.backbone.layer3.4.conv1                                 | Conv2d                  | 262 K \n",
      "282 | detr.backbone.layer3.4.bn1                                   | BatchNorm2d             | 512   \n",
      "283 | detr.backbone.layer3.4.conv2                                 | Conv2d                  | 589 K \n",
      "284 | detr.backbone.layer3.4.bn2                                   | BatchNorm2d             | 512   \n",
      "285 | detr.backbone.layer3.4.conv3                                 | Conv2d                  | 262 K \n",
      "286 | detr.backbone.layer3.4.bn3                                   | BatchNorm2d             | 2 K   \n",
      "287 | detr.backbone.layer3.4.relu                                  | ReLU                    | 0     \n",
      "288 | detr.backbone.layer3.5                                       | Bottleneck              | 1 M   \n",
      "289 | detr.backbone.layer3.5.conv1                                 | Conv2d                  | 262 K \n",
      "290 | detr.backbone.layer3.5.bn1                                   | BatchNorm2d             | 512   \n",
      "291 | detr.backbone.layer3.5.conv2                                 | Conv2d                  | 589 K \n",
      "292 | detr.backbone.layer3.5.bn2                                   | BatchNorm2d             | 512   \n",
      "293 | detr.backbone.layer3.5.conv3                                 | Conv2d                  | 262 K \n",
      "294 | detr.backbone.layer3.5.bn3                                   | BatchNorm2d             | 2 K   \n",
      "295 | detr.backbone.layer3.5.relu                                  | ReLU                    | 0     \n",
      "296 | detr.backbone.layer4                                         | Sequential              | 14 M  \n",
      "297 | detr.backbone.layer4.0                                       | Bottleneck              | 6 M   \n",
      "298 | detr.backbone.layer4.0.conv1                                 | Conv2d                  | 524 K \n",
      "299 | detr.backbone.layer4.0.bn1                                   | BatchNorm2d             | 1 K   \n",
      "300 | detr.backbone.layer4.0.conv2                                 | Conv2d                  | 2 M   \n",
      "301 | detr.backbone.layer4.0.bn2                                   | BatchNorm2d             | 1 K   \n",
      "302 | detr.backbone.layer4.0.conv3                                 | Conv2d                  | 1 M   \n",
      "303 | detr.backbone.layer4.0.bn3                                   | BatchNorm2d             | 4 K   \n",
      "304 | detr.backbone.layer4.0.relu                                  | ReLU                    | 0     \n",
      "305 | detr.backbone.layer4.0.downsample                            | Sequential              | 2 M   \n",
      "306 | detr.backbone.layer4.0.downsample.0                          | Conv2d                  | 2 M   \n",
      "307 | detr.backbone.layer4.0.downsample.1                          | BatchNorm2d             | 4 K   \n",
      "308 | detr.backbone.layer4.1                                       | Bottleneck              | 4 M   \n",
      "309 | detr.backbone.layer4.1.conv1                                 | Conv2d                  | 1 M   \n",
      "310 | detr.backbone.layer4.1.bn1                                   | BatchNorm2d             | 1 K   \n",
      "311 | detr.backbone.layer4.1.conv2                                 | Conv2d                  | 2 M   \n",
      "312 | detr.backbone.layer4.1.bn2                                   | BatchNorm2d             | 1 K   \n",
      "313 | detr.backbone.layer4.1.conv3                                 | Conv2d                  | 1 M   \n",
      "314 | detr.backbone.layer4.1.bn3                                   | BatchNorm2d             | 4 K   \n",
      "315 | detr.backbone.layer4.1.relu                                  | ReLU                    | 0     \n",
      "316 | detr.backbone.layer4.2                                       | Bottleneck              | 4 M   \n",
      "317 | detr.backbone.layer4.2.conv1                                 | Conv2d                  | 1 M   \n",
      "318 | detr.backbone.layer4.2.bn1                                   | BatchNorm2d             | 1 K   \n",
      "319 | detr.backbone.layer4.2.conv2                                 | Conv2d                  | 2 M   \n",
      "320 | detr.backbone.layer4.2.bn2                                   | BatchNorm2d             | 1 K   \n",
      "321 | detr.backbone.layer4.2.conv3                                 | Conv2d                  | 1 M   \n",
      "322 | detr.backbone.layer4.2.bn3                                   | BatchNorm2d             | 4 K   \n",
      "323 | detr.backbone.layer4.2.relu                                  | ReLU                    | 0     \n",
      "324 | detr.backbone.avgpool                                        | AdaptiveAvgPool2d       | 0     \n",
      "325 | detr.conv                                                    | Conv2d                  | 524 K \n",
      "326 | detr.transformer                                             | Transformer             | 17 M  \n",
      "327 | detr.transformer.encoder                                     | TransformerEncoder      | 7 M   \n",
      "328 | detr.transformer.encoder.layers                              | ModuleList              | 7 M   \n",
      "329 | detr.transformer.encoder.layers.0                            | TransformerEncoderLayer | 1 M   \n",
      "330 | detr.transformer.encoder.layers.0.self_attn                  | MultiheadAttention      | 263 K \n",
      "331 | detr.transformer.encoder.layers.0.self_attn.out_proj         | Linear                  | 65 K  \n",
      "332 | detr.transformer.encoder.layers.0.linear1                    | Linear                  | 526 K \n",
      "333 | detr.transformer.encoder.layers.0.dropout                    | Dropout                 | 0     \n",
      "334 | detr.transformer.encoder.layers.0.linear2                    | Linear                  | 524 K \n",
      "335 | detr.transformer.encoder.layers.0.norm1                      | LayerNorm               | 512   \n",
      "336 | detr.transformer.encoder.layers.0.norm2                      | LayerNorm               | 512   \n",
      "337 | detr.transformer.encoder.layers.0.dropout1                   | Dropout                 | 0     \n",
      "338 | detr.transformer.encoder.layers.0.dropout2                   | Dropout                 | 0     \n",
      "339 | detr.transformer.encoder.layers.1                            | TransformerEncoderLayer | 1 M   \n",
      "340 | detr.transformer.encoder.layers.1.self_attn                  | MultiheadAttention      | 263 K \n",
      "341 | detr.transformer.encoder.layers.1.self_attn.out_proj         | Linear                  | 65 K  \n",
      "342 | detr.transformer.encoder.layers.1.linear1                    | Linear                  | 526 K \n",
      "343 | detr.transformer.encoder.layers.1.dropout                    | Dropout                 | 0     \n",
      "344 | detr.transformer.encoder.layers.1.linear2                    | Linear                  | 524 K \n",
      "345 | detr.transformer.encoder.layers.1.norm1                      | LayerNorm               | 512   \n",
      "346 | detr.transformer.encoder.layers.1.norm2                      | LayerNorm               | 512   \n",
      "347 | detr.transformer.encoder.layers.1.dropout1                   | Dropout                 | 0     \n",
      "348 | detr.transformer.encoder.layers.1.dropout2                   | Dropout                 | 0     \n",
      "349 | detr.transformer.encoder.layers.2                            | TransformerEncoderLayer | 1 M   \n",
      "350 | detr.transformer.encoder.layers.2.self_attn                  | MultiheadAttention      | 263 K \n",
      "351 | detr.transformer.encoder.layers.2.self_attn.out_proj         | Linear                  | 65 K  \n",
      "352 | detr.transformer.encoder.layers.2.linear1                    | Linear                  | 526 K \n",
      "353 | detr.transformer.encoder.layers.2.dropout                    | Dropout                 | 0     \n",
      "354 | detr.transformer.encoder.layers.2.linear2                    | Linear                  | 524 K \n",
      "355 | detr.transformer.encoder.layers.2.norm1                      | LayerNorm               | 512   \n",
      "356 | detr.transformer.encoder.layers.2.norm2                      | LayerNorm               | 512   \n",
      "357 | detr.transformer.encoder.layers.2.dropout1                   | Dropout                 | 0     \n",
      "358 | detr.transformer.encoder.layers.2.dropout2                   | Dropout                 | 0     \n",
      "359 | detr.transformer.encoder.layers.3                            | TransformerEncoderLayer | 1 M   \n",
      "360 | detr.transformer.encoder.layers.3.self_attn                  | MultiheadAttention      | 263 K \n",
      "361 | detr.transformer.encoder.layers.3.self_attn.out_proj         | Linear                  | 65 K  \n",
      "362 | detr.transformer.encoder.layers.3.linear1                    | Linear                  | 526 K \n",
      "363 | detr.transformer.encoder.layers.3.dropout                    | Dropout                 | 0     \n",
      "364 | detr.transformer.encoder.layers.3.linear2                    | Linear                  | 524 K \n",
      "365 | detr.transformer.encoder.layers.3.norm1                      | LayerNorm               | 512   \n",
      "366 | detr.transformer.encoder.layers.3.norm2                      | LayerNorm               | 512   \n",
      "367 | detr.transformer.encoder.layers.3.dropout1                   | Dropout                 | 0     \n",
      "368 | detr.transformer.encoder.layers.3.dropout2                   | Dropout                 | 0     \n",
      "369 | detr.transformer.encoder.layers.4                            | TransformerEncoderLayer | 1 M   \n",
      "370 | detr.transformer.encoder.layers.4.self_attn                  | MultiheadAttention      | 263 K \n",
      "371 | detr.transformer.encoder.layers.4.self_attn.out_proj         | Linear                  | 65 K  \n",
      "372 | detr.transformer.encoder.layers.4.linear1                    | Linear                  | 526 K \n",
      "373 | detr.transformer.encoder.layers.4.dropout                    | Dropout                 | 0     \n",
      "374 | detr.transformer.encoder.layers.4.linear2                    | Linear                  | 524 K \n",
      "375 | detr.transformer.encoder.layers.4.norm1                      | LayerNorm               | 512   \n",
      "376 | detr.transformer.encoder.layers.4.norm2                      | LayerNorm               | 512   \n",
      "377 | detr.transformer.encoder.layers.4.dropout1                   | Dropout                 | 0     \n",
      "378 | detr.transformer.encoder.layers.4.dropout2                   | Dropout                 | 0     \n",
      "379 | detr.transformer.encoder.layers.5                            | TransformerEncoderLayer | 1 M   \n",
      "380 | detr.transformer.encoder.layers.5.self_attn                  | MultiheadAttention      | 263 K \n",
      "381 | detr.transformer.encoder.layers.5.self_attn.out_proj         | Linear                  | 65 K  \n",
      "382 | detr.transformer.encoder.layers.5.linear1                    | Linear                  | 526 K \n",
      "383 | detr.transformer.encoder.layers.5.dropout                    | Dropout                 | 0     \n",
      "384 | detr.transformer.encoder.layers.5.linear2                    | Linear                  | 524 K \n",
      "385 | detr.transformer.encoder.layers.5.norm1                      | LayerNorm               | 512   \n",
      "386 | detr.transformer.encoder.layers.5.norm2                      | LayerNorm               | 512   \n",
      "387 | detr.transformer.encoder.layers.5.dropout1                   | Dropout                 | 0     \n",
      "388 | detr.transformer.encoder.layers.5.dropout2                   | Dropout                 | 0     \n",
      "389 | detr.transformer.encoder.norm                                | LayerNorm               | 512   \n",
      "390 | detr.transformer.decoder                                     | TransformerDecoder      | 9 M   \n",
      "391 | detr.transformer.decoder.layers                              | ModuleList              | 9 M   \n",
      "392 | detr.transformer.decoder.layers.0                            | TransformerDecoderLayer | 1 M   \n",
      "393 | detr.transformer.decoder.layers.0.self_attn                  | MultiheadAttention      | 263 K \n",
      "394 | detr.transformer.decoder.layers.0.self_attn.out_proj         | Linear                  | 65 K  \n",
      "395 | detr.transformer.decoder.layers.0.multihead_attn             | MultiheadAttention      | 263 K \n",
      "396 | detr.transformer.decoder.layers.0.multihead_attn.out_proj    | Linear                  | 65 K  \n",
      "397 | detr.transformer.decoder.layers.0.linear1                    | Linear                  | 526 K \n",
      "398 | detr.transformer.decoder.layers.0.dropout                    | Dropout                 | 0     \n",
      "399 | detr.transformer.decoder.layers.0.linear2                    | Linear                  | 524 K \n",
      "400 | detr.transformer.decoder.layers.0.norm1                      | LayerNorm               | 512   \n",
      "401 | detr.transformer.decoder.layers.0.norm2                      | LayerNorm               | 512   \n",
      "402 | detr.transformer.decoder.layers.0.norm3                      | LayerNorm               | 512   \n",
      "403 | detr.transformer.decoder.layers.0.dropout1                   | Dropout                 | 0     \n",
      "404 | detr.transformer.decoder.layers.0.dropout2                   | Dropout                 | 0     \n",
      "405 | detr.transformer.decoder.layers.0.dropout3                   | Dropout                 | 0     \n",
      "406 | detr.transformer.decoder.layers.1                            | TransformerDecoderLayer | 1 M   \n",
      "407 | detr.transformer.decoder.layers.1.self_attn                  | MultiheadAttention      | 263 K \n",
      "408 | detr.transformer.decoder.layers.1.self_attn.out_proj         | Linear                  | 65 K  \n",
      "409 | detr.transformer.decoder.layers.1.multihead_attn             | MultiheadAttention      | 263 K \n",
      "410 | detr.transformer.decoder.layers.1.multihead_attn.out_proj    | Linear                  | 65 K  \n",
      "411 | detr.transformer.decoder.layers.1.linear1                    | Linear                  | 526 K \n",
      "412 | detr.transformer.decoder.layers.1.dropout                    | Dropout                 | 0     \n",
      "413 | detr.transformer.decoder.layers.1.linear2                    | Linear                  | 524 K \n",
      "414 | detr.transformer.decoder.layers.1.norm1                      | LayerNorm               | 512   \n",
      "415 | detr.transformer.decoder.layers.1.norm2                      | LayerNorm               | 512   \n",
      "416 | detr.transformer.decoder.layers.1.norm3                      | LayerNorm               | 512   \n",
      "417 | detr.transformer.decoder.layers.1.dropout1                   | Dropout                 | 0     \n",
      "418 | detr.transformer.decoder.layers.1.dropout2                   | Dropout                 | 0     \n",
      "419 | detr.transformer.decoder.layers.1.dropout3                   | Dropout                 | 0     \n",
      "420 | detr.transformer.decoder.layers.2                            | TransformerDecoderLayer | 1 M   \n",
      "421 | detr.transformer.decoder.layers.2.self_attn                  | MultiheadAttention      | 263 K \n",
      "422 | detr.transformer.decoder.layers.2.self_attn.out_proj         | Linear                  | 65 K  \n",
      "423 | detr.transformer.decoder.layers.2.multihead_attn             | MultiheadAttention      | 263 K \n",
      "424 | detr.transformer.decoder.layers.2.multihead_attn.out_proj    | Linear                  | 65 K  \n",
      "425 | detr.transformer.decoder.layers.2.linear1                    | Linear                  | 526 K \n",
      "426 | detr.transformer.decoder.layers.2.dropout                    | Dropout                 | 0     \n",
      "427 | detr.transformer.decoder.layers.2.linear2                    | Linear                  | 524 K \n",
      "428 | detr.transformer.decoder.layers.2.norm1                      | LayerNorm               | 512   \n",
      "429 | detr.transformer.decoder.layers.2.norm2                      | LayerNorm               | 512   \n",
      "430 | detr.transformer.decoder.layers.2.norm3                      | LayerNorm               | 512   \n",
      "431 | detr.transformer.decoder.layers.2.dropout1                   | Dropout                 | 0     \n",
      "432 | detr.transformer.decoder.layers.2.dropout2                   | Dropout                 | 0     \n",
      "433 | detr.transformer.decoder.layers.2.dropout3                   | Dropout                 | 0     \n",
      "434 | detr.transformer.decoder.layers.3                            | TransformerDecoderLayer | 1 M   \n",
      "435 | detr.transformer.decoder.layers.3.self_attn                  | MultiheadAttention      | 263 K \n",
      "436 | detr.transformer.decoder.layers.3.self_attn.out_proj         | Linear                  | 65 K  \n",
      "437 | detr.transformer.decoder.layers.3.multihead_attn             | MultiheadAttention      | 263 K \n",
      "438 | detr.transformer.decoder.layers.3.multihead_attn.out_proj    | Linear                  | 65 K  \n",
      "439 | detr.transformer.decoder.layers.3.linear1                    | Linear                  | 526 K \n",
      "440 | detr.transformer.decoder.layers.3.dropout                    | Dropout                 | 0     \n",
      "441 | detr.transformer.decoder.layers.3.linear2                    | Linear                  | 524 K \n",
      "442 | detr.transformer.decoder.layers.3.norm1                      | LayerNorm               | 512   \n",
      "443 | detr.transformer.decoder.layers.3.norm2                      | LayerNorm               | 512   \n",
      "444 | detr.transformer.decoder.layers.3.norm3                      | LayerNorm               | 512   \n",
      "445 | detr.transformer.decoder.layers.3.dropout1                   | Dropout                 | 0     \n",
      "446 | detr.transformer.decoder.layers.3.dropout2                   | Dropout                 | 0     \n",
      "447 | detr.transformer.decoder.layers.3.dropout3                   | Dropout                 | 0     \n",
      "448 | detr.transformer.decoder.layers.4                            | TransformerDecoderLayer | 1 M   \n",
      "449 | detr.transformer.decoder.layers.4.self_attn                  | MultiheadAttention      | 263 K \n",
      "450 | detr.transformer.decoder.layers.4.self_attn.out_proj         | Linear                  | 65 K  \n",
      "451 | detr.transformer.decoder.layers.4.multihead_attn             | MultiheadAttention      | 263 K \n",
      "452 | detr.transformer.decoder.layers.4.multihead_attn.out_proj    | Linear                  | 65 K  \n",
      "453 | detr.transformer.decoder.layers.4.linear1                    | Linear                  | 526 K \n",
      "454 | detr.transformer.decoder.layers.4.dropout                    | Dropout                 | 0     \n",
      "455 | detr.transformer.decoder.layers.4.linear2                    | Linear                  | 524 K \n",
      "456 | detr.transformer.decoder.layers.4.norm1                      | LayerNorm               | 512   \n",
      "457 | detr.transformer.decoder.layers.4.norm2                      | LayerNorm               | 512   \n",
      "458 | detr.transformer.decoder.layers.4.norm3                      | LayerNorm               | 512   \n",
      "459 | detr.transformer.decoder.layers.4.dropout1                   | Dropout                 | 0     \n",
      "460 | detr.transformer.decoder.layers.4.dropout2                   | Dropout                 | 0     \n",
      "461 | detr.transformer.decoder.layers.4.dropout3                   | Dropout                 | 0     \n",
      "462 | detr.transformer.decoder.layers.5                            | TransformerDecoderLayer | 1 M   \n",
      "463 | detr.transformer.decoder.layers.5.self_attn                  | MultiheadAttention      | 263 K \n",
      "464 | detr.transformer.decoder.layers.5.self_attn.out_proj         | Linear                  | 65 K  \n",
      "465 | detr.transformer.decoder.layers.5.multihead_attn             | MultiheadAttention      | 263 K \n",
      "466 | detr.transformer.decoder.layers.5.multihead_attn.out_proj    | Linear                  | 65 K  \n",
      "467 | detr.transformer.decoder.layers.5.linear1                    | Linear                  | 526 K \n",
      "468 | detr.transformer.decoder.layers.5.dropout                    | Dropout                 | 0     \n",
      "469 | detr.transformer.decoder.layers.5.linear2                    | Linear                  | 524 K \n",
      "470 | detr.transformer.decoder.layers.5.norm1                      | LayerNorm               | 512   \n",
      "471 | detr.transformer.decoder.layers.5.norm2                      | LayerNorm               | 512   \n",
      "472 | detr.transformer.decoder.layers.5.norm3                      | LayerNorm               | 512   \n",
      "473 | detr.transformer.decoder.layers.5.dropout1                   | Dropout                 | 0     \n",
      "474 | detr.transformer.decoder.layers.5.dropout2                   | Dropout                 | 0     \n",
      "475 | detr.transformer.decoder.layers.5.dropout3                   | Dropout                 | 0     \n",
      "476 | detr.transformer.decoder.norm                                | LayerNorm               | 512   \n",
      "477 | detr.linear_class                                            | Linear                  | 23 K  \n",
      "478 | detr.linear_bbox                                             | Linear                  | 1 K   \n",
      "479 | classifier                                                   | Linear                  | 83 M  \n",
      "480 | drop_out                                                     | Dropout                 | 0     \n",
      "481 | log_softmax                                                  | LogSoftmax              | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314b5316cdc7448ab4ba5e85d3625dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0398132596a54c6e8522a0dd139073b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f2f6d2aabec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#trainer = Trainer(gpus=4, max_epochs=20,log_gpu_memory=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast_dev_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvqa_detr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;31m# return 1 when finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m     def test(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# fast_dev_run always forces val checking after train batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_dev_run\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshould_check_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_checkpoint_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_early_stop_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test_mode)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# run evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog_bar_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, model, dataloaders, max_batches, test_mode)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_device_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "#trainer = Trainer(gpus=4, max_epochs=20,log_gpu_memory=True)\n",
    "trainer = Trainer(fast_dev_run=True)\n",
    "trainer.fit(vqa_detr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpsKfzoTPvN9",
    "outputId": "525e0c17-ba8b-466b-d06f-4492603a75c1"
   },
   "outputs": [],
   "source": [
    "# Start tensorboard.\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir kaggle/working/lightning_logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lkixu9cEiuH4"
   },
   "outputs": [],
   "source": [
    "model_save= vqa_detr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmkzyZD2lms4"
   },
   "outputs": [],
   "source": [
    "model_save.eval().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LocAAdSLiyoJ",
    "outputId": "028c6b0f-d539-417e-d884-692b93bf0ac9"
   },
   "outputs": [],
   "source": [
    "img,q,a=vqa_data[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0C9hbUzjA7j",
    "outputId": "07631c7f-d64e-43be-e593-ef7fe28bfddd"
   },
   "outputs": [],
   "source": [
    "\n",
    "out = model_save(img.unsqueeze(0),q['ids'].unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p672z_Qvjh2l"
   },
   "outputs": [],
   "source": [
    "a,index = out['logits'].max(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lB5ULieHlM7I",
    "outputId": "30b263f8-2f36-4c62-c944-d17fa6ecfa6f"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer.convert_ids_to_tokens(q['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bvtBHGVkDr5",
    "outputId": "57c04b54-e2f8-4b89-aa2f-18486a138ddc"
   },
   "outputs": [],
   "source": [
    "all_answers[int(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2RgCuljj0rA",
    "outputId": "0a969671-b7ac-4bf3-d9f6-9c6323dba0a7"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYwwjn7cg5LL",
    "outputId": "4f9ea055-089a-4e73-d727-40623c891fda"
   },
   "outputs": [],
   "source": [
    "while 1:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzGeoINdgUkg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xeUiwvNxg5IL",
    "outputId": "d016ae3b-bdb4-43a4-feaf-f5e9b673f147"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxWysSRHg5GM",
    "outputId": "4597a5b0-57e0-48e6-9fd2-63346294fce5"
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7E47VdQBYim",
    "outputId": "740f2c14-14aa-4500-e039-bfda773c20a5"
   },
   "outputs": [],
   "source": [
    "output.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kRrRu0Pg5CD",
    "outputId": "fa93fa9f-f554-46bf-8eb9-2f037c22789a"
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 2])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KB1c-xPkg4_7"
   },
   "outputs": [],
   "source": [
    "z=np.expand_dims(x, axis=-1)\n",
    "np.repeat(z,3,axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HC7x-7cgg48D",
    "outputId": "eceb7049-1453-49c7-ab64-298391547a3d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMYEVVN6g46I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eW4yYVKkg42L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jN4YyXjspxbR"
   },
   "outputs": [],
   "source": [
    "for im,q,a in data_loader:\n",
    "    print(im.shape)\n",
    "    print(q['ids'].shape)\n",
    "    print(a.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdEvUm4kDjvx",
    "outputId": "5d64ecf0-9113-4ed4-884d-ab672c7a98ce"
   },
   "outputs": [],
   "source": [
    "len(answer_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EX7BA0oNFVc"
   },
   "outputs": [],
   "source": [
    "img,q,a=vqa_data[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJExIYdDGwlC"
   },
   "outputs": [],
   "source": [
    "a,b=torch.max(a.unsqueeze(0),dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9ad7adt54T7",
    "outputId": "44a748ef-865c-4ba6-d8a4-710325d74af6"
   },
   "outputs": [],
   "source": [
    "b.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72e-rwiQNFLF",
    "outputId": "fbe9d96a-5881-4e41-dc2a-12963ab48a17"
   },
   "outputs": [],
   "source": [
    "a.unsqueeze(0).view(-1,1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0R64hJAnvC4"
   },
   "outputs": [],
   "source": [
    "bert_config = BertConfig(hidden_size=256, num_attention_heads=8, num_hidden_layers=6)\n",
    "bert_decoder_config = BertConfig(is_decoder=True, hidden_size=256, num_attention_heads=8, num_hidden_layers=6)\n",
    "\n",
    "enc_dec_config = EncoderDecoderConfig.from_encoder_decoder_configs(encoder_config= bert_config, decoder_config= bert_decoder_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcNZWDKPlRlN"
   },
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel(config= enc_dec_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfZOXxIFlZK9"
   },
   "outputs": [],
   "source": [
    "outputs = model(input_ids = q['ids'].unsqueeze(0), decoder_inputs_embeds = h[0].unsqueeze(0).flatten(2).permute(2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsjQtkw0mGv_"
   },
   "outputs": [],
   "source": [
    "outputs[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8H-1gtoRmWI"
   },
   "outputs": [],
   "source": [
    "bert_decoder = BertModel(config  = bert_decoder_config)\n",
    "outputs = bert_decoder(input_ids = q['ids'].unsqueeze(0), encoder_hidden_states = h[0].unsqueeze(0).flatten(2).permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fpRcCBhSe63"
   },
   "outputs": [],
   "source": [
    "outputs = bert_decoder(input_ids = q['ids'].unsqueeze(0), encoder_hidden_states = h[0].unsqueeze(0).flatten(2).permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6q0BavU9BHN"
   },
   "outputs": [],
   "source": [
    "while 1 :\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-91LWQZDc1wK"
   },
   "outputs": [],
   "source": [
    "BertModel??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlIue81hy08k"
   },
   "outputs": [],
   "source": [
    " h[0].unsqueeze(0).flatten(2).permute(0, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYLN4RJRXXuZ"
   },
   "outputs": [],
   "source": [
    "q['ids'].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiLAyykeXx_G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}